{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer.IO Data Pipelines API - Advanced Event Tracking\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates advanced event tracking capabilities with Customer.IO's Data Pipelines API.\n",
    "It covers complex user journeys, funnel analysis, behavioral patterns, advanced attribution, and sophisticated event sequencing with proper validation and error handling.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Complete setup from `00_setup_and_configuration.ipynb`\n",
    "- Complete authentication setup from `01_authentication_and_utilities.ipynb`\n",
    "- Understanding of basic event tracking from `03_events_and_tracking.ipynb`\n",
    "- Customer.IO API key configured in Databricks secrets\n",
    "- Understanding of advanced analytics concepts\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **User Journeys**: Multi-step user interactions across touchpoints\n",
    "- **Funnel Analysis**: Conversion tracking through defined steps\n",
    "- **Behavioral Patterns**: Identifying user behavior clusters and segments\n",
    "- **Attribution Modeling**: Multi-touch attribution for conversions\n",
    "- **Event Sequencing**: Time-based event pattern analysis\n",
    "- **Cohort Analysis**: User behavior analysis over time periods\n",
    "\n",
    "## Advanced Tracking Types Covered\n",
    "\n",
    "1. **User Journey Mapping**: Complete user path analysis\n",
    "2. **Conversion Funnels**: Multi-step conversion tracking\n",
    "3. **Behavioral Segmentation**: Dynamic user categorization\n",
    "4. **Attribution Analysis**: Multi-touch conversion attribution\n",
    "5. **Retention Cohorts**: Long-term user engagement tracking\n",
    "6. **Real-time Analytics**: Live event stream processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Dict, List, Optional, Any, Union, Set, Tuple\n",
    "import json\n",
    "import uuid\n",
    "from enum import Enum\n",
    "from collections import defaultdict, deque\n",
    "import statistics\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "print(\"SUCCESS: Standard libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add utils directory to Python path\n",
    "sys.path.append('/Workspace/Repos/customer_io_notebooks/utils')\n",
    "print(\"SUCCESS: Utils directory added to Python path\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import Customer.IO API utilities and EventManager\nfrom utils.api_client import CustomerIOClient\nfrom utils.event_manager import (\n    EventManager, \n    EventTemplate, \n    EventCategory, \n    EventPriority,\n    EventSession\n)\nfrom utils.validators import (\n    TrackRequest,\n    validate_request_size,\n    create_context\n)\n\nprint(\"SUCCESS: Customer.IO API utilities and EventManager imported\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transformation utilities\n",
    "from utils.transformers import (\n",
    "    BatchTransformer,\n",
    "    ContextTransformer\n",
    ")\n",
    "\n",
    "print(\"SUCCESS: Transformation utilities imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import error handling utilities\n",
    "from utils.error_handlers import (\n",
    "    CustomerIOError,\n",
    "    RateLimitError,\n",
    "    ValidationError,\n",
    "    NetworkError,\n",
    "    retry_on_error,\n",
    "    ErrorContext\n",
    ")\n",
    "\n",
    "print(\"SUCCESS: Error handling utilities imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Databricks and Spark utilities\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "print(\"SUCCESS: Databricks and Spark utilities imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import validation and logging\n",
    "import structlog\n",
    "from pydantic import ValidationError as PydanticValidationError, BaseModel, Field, validator\n",
    "\n",
    "# Initialize logger\n",
    "logger = structlog.get_logger(\"advanced_tracking\")\n",
    "\n",
    "print(\"SUCCESS: Validation and logging initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from setup notebook (secure approach)\n",
    "try:\n",
    "    CUSTOMERIO_REGION = dbutils.widgets.get(\"customerio_region\") or \"us\"\n",
    "    DATABASE_NAME = dbutils.widgets.get(\"database_name\") or \"customerio_demo\"\n",
    "    CATALOG_NAME = dbutils.widgets.get(\"catalog_name\") or \"main\"\n",
    "    ENVIRONMENT = dbutils.widgets.get(\"environment\") or \"test\"\n",
    "    \n",
    "    print(f\"Configuration loaded from setup notebook:\")\n",
    "    print(f\"  Region: {CUSTOMERIO_REGION}\")\n",
    "    print(f\"  Database: {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "    print(f\"  Environment: {ENVIRONMENT}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"WARNING: Could not load configuration from setup notebook: {str(e)}\")\n",
    "    print(\"INFO: Using fallback configuration\")\n",
    "    CUSTOMERIO_REGION = \"us\"\n",
    "    DATABASE_NAME = \"customerio_demo\"\n",
    "    CATALOG_NAME = \"main\"\n",
    "    ENVIRONMENT = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Customer.IO API key from secure storage\n",
    "CUSTOMERIO_API_KEY = dbutils.secrets.get(\"customerio\", \"api_key\")\n",
    "print(\"SUCCESS: Customer.IO API key retrieved from secure storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark to use the specified database\n",
    "spark.sql(f\"USE {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "print(\"SUCCESS: Database configured\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the Customer.IO client and EventManager\ntry:\n    client = CustomerIOClient(\n        api_key=CUSTOMERIO_API_KEY,\n        region=CUSTOMERIO_REGION,\n        timeout=30,\n        max_retries=3,\n        retry_backoff_factor=2.0,\n        enable_logging=True,\n        spark_session=spark\n    )\n    \n    # Initialize EventManager for advanced tracking\n    event_manager = EventManager(client)\n    \n    print(\"SUCCESS: Customer.IO client and EventManager initialized for advanced tracking\")\n    \nexcept Exception as e:\n    print(f\"ERROR: Failed to initialize Customer.IO client: {str(e)}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Driven Development: Advanced Tracking Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test user journey validation using EventManager concepts\n\ndef test_user_journey_validation():\n    \"\"\"Test that user journeys have proper step structure and sequencing.\"\"\"\n    \n    # Test valid user journey using EventManager approach\n    try:\n        # Create events that represent journey steps\n        landing_event = event_manager.create_event(\n            user_id=\"user_test_001\",\n            template_name=\"page_viewed\",\n            properties={\n                \"page_name\": \"Landing\",\n                \"url\": \"/landing\",\n                \"source\": \"google\"\n            }\n        )\n        \n        signup_event = event_manager.create_event(\n            user_id=\"user_test_001\", \n            template_name=\"feature_used\",\n            properties={\n                \"feature_name\": \"registration\",\n                \"action\": \"form_submitted\"\n            }\n        )\n        \n        # Validate event structure\n        assert \"userId\" in landing_event\n        assert \"event\" in landing_event\n        assert \"properties\" in landing_event\n        assert landing_event[\"userId\"] == \"user_test_001\"\n        \n        print(\"SUCCESS: User journey validation test passed\")\n        return True\n    except Exception as e:\n        print(f\"ERROR: User journey validation test failed: {str(e)}\")\n        return False\n\n# Run the test\ntest_user_journey_validation()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test funnel progression validation\n\ndef test_funnel_progression_validation():\n    \"\"\"Test that funnel steps follow logical progression.\"\"\"\n    \n    # Test valid funnel progression\n    funnel_steps = [\n        {\"step\": \"awareness\", \"order\": 1, \"required\": True},\n        {\"step\": \"interest\", \"order\": 2, \"required\": True},\n        {\"step\": \"consideration\", \"order\": 3, \"required\": False},\n        {\"step\": \"conversion\", \"order\": 4, \"required\": True}\n    ]\n    \n    # Validate order sequence\n    orders = [step[\"order\"] for step in funnel_steps]\n    if orders != sorted(orders):\n        print(\"ERROR: Funnel steps not in correct order\")\n        return False\n    \n    # Validate unique step names\n    step_names = [step[\"step\"] for step in funnel_steps]\n    if len(step_names) != len(set(step_names)):\n        print(\"ERROR: Duplicate funnel step names\")\n        return False\n    \n    # Validate at least one required step\n    required_steps = [step for step in funnel_steps if step[\"required\"]]\n    if not required_steps:\n        print(\"ERROR: No required funnel steps defined\")\n        return False\n    \n    print(\"SUCCESS: Funnel progression validation test passed\")\n    return True\n\n# Run the test\ntest_funnel_progression_validation()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test attribution model validation\n\ndef test_attribution_model_validation():\n    \"\"\"Test that attribution models have proper touchpoint weighting.\"\"\"\n    \n    # Test first-touch attribution\n    first_touch_weights = [1.0, 0.0, 0.0, 0.0]  # 4 touchpoints\n    if abs(sum(first_touch_weights) - 1.0) > 0.001:\n        print(\"ERROR: First-touch attribution weights don't sum to 1.0\")\n        return False\n    \n    # Test linear attribution\n    linear_weights = [0.25, 0.25, 0.25, 0.25]  # 4 touchpoints\n    if abs(sum(linear_weights) - 1.0) > 0.001:\n        print(\"ERROR: Linear attribution weights don't sum to 1.0\")\n        return False\n    \n    # Test time-decay attribution\n    time_decay_weights = [0.1, 0.2, 0.3, 0.4]  # More recent gets higher weight\n    if abs(sum(time_decay_weights) - 1.0) > 0.001:\n        print(\"ERROR: Time-decay attribution weights don't sum to 1.0\")\n        return False\n    \n    # Validate time decay increases over time\n    if time_decay_weights != sorted(time_decay_weights):\n        print(\"ERROR: Time-decay weights should increase for recent touchpoints\")\n        return False\n    \n    print(\"SUCCESS: Attribution model validation test passed\")\n    return True\n\n# Run the test\ntest_attribution_model_validation()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Event Types and Enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define advanced tracking enumerations\n",
    "class JourneyStage(str, Enum):\n",
    "    \"\"\"Enumeration for user journey stages.\"\"\"\n",
    "    AWARENESS = \"awareness\"\n",
    "    INTEREST = \"interest\"\n",
    "    CONSIDERATION = \"consideration\"\n",
    "    CONVERSION = \"conversion\"\n",
    "    RETENTION = \"retention\"\n",
    "    ADVOCACY = \"advocacy\"\n",
    "\n",
    "class FunnelType(str, Enum):\n",
    "    \"\"\"Enumeration for funnel types.\"\"\"\n",
    "    ACQUISITION = \"acquisition\"\n",
    "    ACTIVATION = \"activation\"\n",
    "    RETENTION = \"retention\"\n",
    "    REVENUE = \"revenue\"\n",
    "    REFERRAL = \"referral\"\n",
    "    CUSTOM = \"custom\"\n",
    "\n",
    "class AttributionModel(str, Enum):\n",
    "    \"\"\"Enumeration for attribution models.\"\"\"\n",
    "    FIRST_TOUCH = \"first_touch\"\n",
    "    LAST_TOUCH = \"last_touch\"\n",
    "    LINEAR = \"linear\"\n",
    "    TIME_DECAY = \"time_decay\"\n",
    "    POSITION_BASED = \"position_based\"\n",
    "    CUSTOM = \"custom\"\n",
    "\n",
    "class SegmentationType(str, Enum):\n",
    "    \"\"\"Enumeration for user segmentation types.\"\"\"\n",
    "    BEHAVIORAL = \"behavioral\"\n",
    "    DEMOGRAPHIC = \"demographic\"\n",
    "    PSYCHOGRAPHIC = \"psychographic\"\n",
    "    GEOGRAPHIC = \"geographic\"\n",
    "    TECHNOGRAPHIC = \"technographic\"\n",
    "    VALUE_BASED = \"value_based\"\n",
    "\n",
    "print(\"SUCCESS: Advanced tracking enumerations defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type-Safe Advanced Tracking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define journey step model\n",
    "class JourneyStep(BaseModel):\n",
    "    \"\"\"Type-safe journey step model.\"\"\"\n",
    "    step_id: str = Field(..., description=\"Unique step identifier\")\n",
    "    event: str = Field(..., description=\"Event name\")\n",
    "    timestamp: datetime = Field(..., description=\"Step timestamp\")\n",
    "    properties: Dict[str, Any] = Field(default_factory=dict, description=\"Step properties\")\n",
    "    stage: Optional[JourneyStage] = Field(None, description=\"Journey stage\")\n",
    "    duration_seconds: Optional[float] = Field(None, ge=0, description=\"Time spent in step\")\n",
    "    \n",
    "    @validator('step_id')\n",
    "    def validate_step_id(cls, v: str) -> str:\n",
    "        \"\"\"Validate step ID format.\"\"\"\n",
    "        if not v or len(v.strip()) == 0:\n",
    "            raise ValueError(\"Step ID cannot be empty\")\n",
    "        return v.strip().lower()\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: JourneyStep model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user journey model\n",
    "class UserJourney(BaseModel):\n",
    "    \"\"\"Type-safe user journey model.\"\"\"\n",
    "    journey_id: str = Field(..., description=\"Unique journey identifier\")\n",
    "    user_id: str = Field(..., description=\"User identifier\")\n",
    "    journey_type: str = Field(..., description=\"Type of journey\")\n",
    "    steps: List[JourneyStep] = Field(default_factory=list, description=\"Journey steps\")\n",
    "    started_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    completed_at: Optional[datetime] = Field(None, description=\"Journey completion time\")\n",
    "    is_completed: bool = Field(default=False, description=\"Journey completion status\")\n",
    "    conversion_value: Optional[float] = Field(None, ge=0, description=\"Conversion value\")\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Journey metadata\")\n",
    "    \n",
    "    @validator('journey_id', 'user_id')\n",
    "    def validate_ids(cls, v: str) -> str:\n",
    "        \"\"\"Validate ID formats.\"\"\"\n",
    "        if not v or len(v.strip()) == 0:\n",
    "            raise ValueError(\"ID cannot be empty\")\n",
    "        return v.strip()\n",
    "    \n",
    "    @validator('steps')\n",
    "    def validate_step_order(cls, v: List[JourneyStep]) -> List[JourneyStep]:\n",
    "        \"\"\"Validate steps are in chronological order.\"\"\"\n",
    "        if len(v) > 1:\n",
    "            for i in range(1, len(v)):\n",
    "                if v[i].timestamp < v[i-1].timestamp:\n",
    "                    raise ValueError(\"Journey steps must be in chronological order\")\n",
    "        return v\n",
    "    \n",
    "    def add_step(self, step: JourneyStep) -> None:\n",
    "        \"\"\"Add a step to the journey.\"\"\"\n",
    "        self.steps.append(step)\n",
    "        self.steps.sort(key=lambda x: x.timestamp)\n",
    "    \n",
    "    def get_duration_minutes(self) -> Optional[float]:\n",
    "        \"\"\"Get total journey duration in minutes.\"\"\"\n",
    "        if not self.steps:\n",
    "            return None\n",
    "        \n",
    "        start_time = self.steps[0].timestamp\n",
    "        end_time = self.completed_at or self.steps[-1].timestamp\n",
    "        \n",
    "        return (end_time - start_time).total_seconds() / 60\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: UserJourney model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funnel model\n",
    "class FunnelStep(BaseModel):\n",
    "    \"\"\"Type-safe funnel step model.\"\"\"\n",
    "    step_name: str = Field(..., description=\"Step name\")\n",
    "    step_order: int = Field(..., ge=1, description=\"Step order in funnel\")\n",
    "    event_patterns: List[str] = Field(..., description=\"Event patterns that match this step\")\n",
    "    required: bool = Field(default=True, description=\"Whether step is required\")\n",
    "    time_window_hours: Optional[int] = Field(None, ge=1, description=\"Time window for step completion\")\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        validate_assignment = True\n",
    "\n",
    "class ConversionFunnel(BaseModel):\n",
    "    \"\"\"Type-safe conversion funnel model.\"\"\"\n",
    "    funnel_id: str = Field(..., description=\"Unique funnel identifier\")\n",
    "    funnel_name: str = Field(..., description=\"Funnel name\")\n",
    "    funnel_type: FunnelType = Field(..., description=\"Type of funnel\")\n",
    "    steps: List[FunnelStep] = Field(..., description=\"Funnel steps\")\n",
    "    attribution_model: AttributionModel = Field(default=AttributionModel.LAST_TOUCH)\n",
    "    lookback_days: int = Field(default=30, ge=1, le=365, description=\"Attribution lookback period\")\n",
    "    \n",
    "    @validator('steps')\n",
    "    def validate_step_order(cls, v: List[FunnelStep]) -> List[FunnelStep]:\n",
    "        \"\"\"Validate steps are in correct order.\"\"\"\n",
    "        if not v:\n",
    "            raise ValueError(\"Funnel must have at least one step\")\n",
    "        \n",
    "        orders = [step.step_order for step in v]\n",
    "        if orders != sorted(orders):\n",
    "            raise ValueError(\"Funnel steps must be in sequential order\")\n",
    "        \n",
    "        # Check for duplicate orders\n",
    "        if len(orders) != len(set(orders)):\n",
    "            raise ValueError(\"Funnel steps cannot have duplicate order numbers\")\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: ConversionFunnel model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribution touchpoint model\n",
    "class AttributionTouchpoint(BaseModel):\n",
    "    \"\"\"Type-safe attribution touchpoint model.\"\"\"\n",
    "    touchpoint_id: str = Field(..., description=\"Unique touchpoint identifier\")\n",
    "    user_id: str = Field(..., description=\"User identifier\")\n",
    "    channel: str = Field(..., description=\"Marketing channel\")\n",
    "    campaign: Optional[str] = Field(None, description=\"Campaign identifier\")\n",
    "    source: Optional[str] = Field(None, description=\"Traffic source\")\n",
    "    medium: Optional[str] = Field(None, description=\"Traffic medium\")\n",
    "    content: Optional[str] = Field(None, description=\"Content identifier\")\n",
    "    timestamp: datetime = Field(..., description=\"Touchpoint timestamp\")\n",
    "    conversion_value: Optional[float] = Field(None, ge=0, description=\"Associated conversion value\")\n",
    "    position_in_journey: int = Field(..., ge=1, description=\"Position in customer journey\")\n",
    "    \n",
    "    @validator('touchpoint_id', 'user_id', 'channel')\n",
    "    def validate_required_fields(cls, v: str) -> str:\n",
    "        \"\"\"Validate required fields are not empty.\"\"\"\n",
    "        if not v or len(v.strip()) == 0:\n",
    "            raise ValueError(\"Field cannot be empty\")\n",
    "        return v.strip()\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: AttributionTouchpoint model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Journey Tracking Implementation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create user journey using EventManager\n\n# Register custom journey templates with EventManager\njourney_start_template = EventTemplate(\n    name=\"Journey Started\",\n    category=EventCategory.LIFECYCLE,\n    priority=EventPriority.HIGH,\n    required_properties=[\"journey_type\", \"source\"],\n    default_properties={\"platform\": \"web\"}\n)\n\njourney_step_template = EventTemplate(\n    name=\"Journey Step Completed\",\n    category=EventCategory.LIFECYCLE,\n    priority=EventPriority.NORMAL,\n    required_properties=[\"step_id\", \"step_name\"],\n    default_properties={}\n)\n\nevent_manager.register_template(journey_start_template)\nevent_manager.register_template(journey_step_template)\n\nprint(\"SUCCESS: Journey templates registered with EventManager\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create journey events using EventManager\n\n# Start user journey\njourney_start_event = event_manager.create_event(\n    user_id=\"user_advanced_001\",\n    template_name=\"journey_started\",\n    properties={\n        \"journey_type\": \"onboarding\",\n        \"source\": \"google\",\n        \"campaign\": \"brand_awareness\",\n        \"journey_id\": \"journey_advanced_001\"\n    }\n)\n\n# Create journey step events\nstep_events = []\n\n# Landing page step\nlanding_step = event_manager.create_event(\n    user_id=\"user_advanced_001\",\n    template_name=\"page_viewed\",\n    properties={\n        \"page_name\": \"Landing\",\n        \"url\": \"/landing\",\n        \"source\": \"google\",\n        \"journey_id\": \"journey_advanced_001\",\n        \"step_order\": 1\n    },\n    timestamp=datetime.now(timezone.utc)\n)\nstep_events.append(landing_step)\n\nprint(\"Journey events created using EventManager:\")\nprint(f\"  Journey start: {journey_start_event['event']}\")\nprint(f\"  Step events: {len(step_events)}\")\nprint(f\"  User: {journey_start_event['userId']}\")\nprint(f\"  Journey ID: {journey_start_event['properties']['journey_id']}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Add more journey step events using EventManager\n\n# Signup form step\nsignup_form_step = event_manager.create_event(\n    user_id=\"user_advanced_001\",\n    template_name=\"page_viewed\",\n    properties={\n        \"page_name\": \"Signup Form\",\n        \"url\": \"/signup\",\n        \"journey_id\": \"journey_advanced_001\",\n        \"step_order\": 2,\n        \"form_name\": \"registration\"\n    },\n    timestamp=datetime.now(timezone.utc) + timedelta(minutes=2)\n)\nstep_events.append(signup_form_step)\n\n# Form completion step\nform_completion_step = event_manager.create_event(\n    user_id=\"user_advanced_001\",\n    template_name=\"feature_used\",\n    properties={\n        \"feature_name\": \"registration_form\",\n        \"action\": \"form_submitted\",\n        \"journey_id\": \"journey_advanced_001\",\n        \"step_order\": 3,\n        \"form_fields_completed\": [\"email\", \"password\", \"name\"]\n    },\n    timestamp=datetime.now(timezone.utc) + timedelta(minutes=5)\n)\nstep_events.append(form_completion_step)\n\nprint(f\"Total journey step events: {len(step_events)}\")\nfor i, step in enumerate(step_events, 1):\n    print(f\"  {i}. {step['event']} - {step['properties'].get('page_name', step['properties'].get('feature_name', 'Unknown'))}\")\n    print(f\"     Step order: {step['properties'].get('step_order', 'N/A')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Funnel Analysis Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Create conversion funnel\n",
    "def create_conversion_funnel(\n",
    "    funnel_name: str,\n",
    "    funnel_type: FunnelType,\n",
    "    step_definitions: List[Dict[str, Any]]\n",
    ") -> ConversionFunnel:\n",
    "    \"\"\"Create a conversion funnel with defined steps.\"\"\"\n",
    "    \n",
    "    funnel_id = f\"funnel_{funnel_name.lower().replace(' ', '_')}_{int(datetime.now().timestamp())}\"\n",
    "    \n",
    "    # Create funnel steps\n",
    "    steps = []\n",
    "    for step_def in step_definitions:\n",
    "        step = FunnelStep(**step_def)\n",
    "        steps.append(step)\n",
    "    \n",
    "    funnel = ConversionFunnel(\n",
    "        funnel_id=funnel_id,\n",
    "        funnel_name=funnel_name,\n",
    "        funnel_type=funnel_type,\n",
    "        steps=steps\n",
    "    )\n",
    "    \n",
    "    return funnel\n",
    "\n",
    "# Create sample onboarding funnel\n",
    "onboarding_steps = [\n",
    "    {\n",
    "        \"step_name\": \"Landing Page Visit\",\n",
    "        \"step_order\": 1,\n",
    "        \"event_patterns\": [\"Page Viewed\"],\n",
    "        \"required\": True,\n",
    "        \"time_window_hours\": 24\n",
    "    },\n",
    "    {\n",
    "        \"step_name\": \"Signup Form Interaction\",\n",
    "        \"step_order\": 2,\n",
    "        \"event_patterns\": [\"Form Viewed\", \"Form Field Completed\"],\n",
    "        \"required\": True,\n",
    "        \"time_window_hours\": 2\n",
    "    },\n",
    "    {\n",
    "        \"step_name\": \"Account Creation\",\n",
    "        \"step_order\": 3,\n",
    "        \"event_patterns\": [\"User Registered\"],\n",
    "        \"required\": True,\n",
    "        \"time_window_hours\": 1\n",
    "    },\n",
    "    {\n",
    "        \"step_name\": \"Email Verification\",\n",
    "        \"step_order\": 4,\n",
    "        \"event_patterns\": [\"Email Verified\"],\n",
    "        \"required\": False,\n",
    "        \"time_window_hours\": 48\n",
    "    }\n",
    "]\n",
    "\n",
    "onboarding_funnel = create_conversion_funnel(\n",
    "    funnel_name=\"User Onboarding\",\n",
    "    funnel_type=FunnelType.ACQUISITION,\n",
    "    step_definitions=onboarding_steps\n",
    ")\n",
    "\n",
    "print(\"Conversion funnel created:\")\n",
    "print(f\"  Funnel ID: {onboarding_funnel.funnel_id}\")\n",
    "print(f\"  Name: {onboarding_funnel.funnel_name}\")\n",
    "print(f\"  Type: {onboarding_funnel.funnel_type}\")\n",
    "print(f\"  Steps: {len(onboarding_funnel.steps)}\")\n",
    "\n",
    "for step in onboarding_funnel.steps:\n",
    "    print(f\"    {step.step_order}. {step.step_name} ({'required' if step.required else 'optional'})\")\n",
    "    print(f\"       Events: {', '.join(step.event_patterns)}\")\n",
    "    print(f\"       Time window: {step.time_window_hours} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Analyze funnel conversion rates\n",
    "def analyze_funnel_conversion(\n",
    "    funnel: ConversionFunnel,\n",
    "    user_journeys: List[UserJourney]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Analyze conversion rates for a funnel based on user journeys.\"\"\"\n",
    "    \n",
    "    # Initialize step counters\n",
    "    step_counts = {step.step_name: 0 for step in funnel.steps}\n",
    "    step_events = {step.step_name: step.event_patterns for step in funnel.steps}\n",
    "    \n",
    "    # Analyze each journey\n",
    "    total_users = len(user_journeys)\n",
    "    completed_journeys = 0\n",
    "    \n",
    "    for journey in user_journeys:\n",
    "        journey_events = [step.event for step in journey.steps]\n",
    "        \n",
    "        # Check which funnel steps this journey completed\n",
    "        for funnel_step in funnel.steps:\n",
    "            step_completed = any(\n",
    "                event_pattern in journey_events \n",
    "                for event_pattern in funnel_step.event_patterns\n",
    "            )\n",
    "            \n",
    "            if step_completed:\n",
    "                step_counts[funnel_step.step_name] += 1\n",
    "        \n",
    "        # Check if journey is completed\n",
    "        if journey.is_completed:\n",
    "            completed_journeys += 1\n",
    "    \n",
    "    # Calculate conversion rates\n",
    "    conversion_rates = {}\n",
    "    step_names = [step.step_name for step in sorted(funnel.steps, key=lambda x: x.step_order)]\n",
    "    \n",
    "    for i, step_name in enumerate(step_names):\n",
    "        if i == 0:\n",
    "            # First step conversion rate (vs total users)\n",
    "            conversion_rates[step_name] = {\n",
    "                \"users\": step_counts[step_name],\n",
    "                \"conversion_rate\": step_counts[step_name] / total_users if total_users > 0 else 0,\n",
    "                \"drop_off_rate\": 1 - (step_counts[step_name] / total_users if total_users > 0 else 0)\n",
    "            }\n",
    "        else:\n",
    "            # Subsequent steps (vs previous step)\n",
    "            previous_step = step_names[i-1]\n",
    "            previous_count = step_counts[previous_step]\n",
    "            \n",
    "            conversion_rates[step_name] = {\n",
    "                \"users\": step_counts[step_name],\n",
    "                \"conversion_rate\": step_counts[step_name] / previous_count if previous_count > 0 else 0,\n",
    "                \"drop_off_rate\": 1 - (step_counts[step_name] / previous_count if previous_count > 0 else 0)\n",
    "            }\n",
    "    \n",
    "    # Overall funnel metrics\n",
    "    first_step_count = step_counts[step_names[0]] if step_names else 0\n",
    "    last_step_count = step_counts[step_names[-1]] if step_names else 0\n",
    "    \n",
    "    analysis = {\n",
    "        \"funnel_id\": funnel.funnel_id,\n",
    "        \"funnel_name\": funnel.funnel_name,\n",
    "        \"total_users\": total_users,\n",
    "        \"completed_journeys\": completed_journeys,\n",
    "        \"overall_conversion_rate\": last_step_count / first_step_count if first_step_count > 0 else 0,\n",
    "        \"step_analysis\": conversion_rates,\n",
    "        \"analyzed_at\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze the funnel with sample data (using our created journey)\n",
    "sample_journeys = [user_journey]  # In practice, this would be a larger dataset\n",
    "\n",
    "funnel_analysis = analyze_funnel_conversion(\n",
    "    funnel=onboarding_funnel,\n",
    "    user_journeys=sample_journeys\n",
    ")\n",
    "\n",
    "print(\"Funnel analysis results:\")\n",
    "print(json.dumps(funnel_analysis, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution Modeling Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Create attribution touchpoints\n",
    "def create_attribution_touchpoints(\n",
    "    user_id: str,\n",
    "    touchpoint_data: List[Dict[str, Any]]\n",
    ") -> List[AttributionTouchpoint]:\n",
    "    \"\"\"Create attribution touchpoints for a user's journey.\"\"\"\n",
    "    \n",
    "    touchpoints = []\n",
    "    \n",
    "    for i, data in enumerate(touchpoint_data, 1):\n",
    "        touchpoint_id = f\"tp_{user_id}_{i}_{int(data['timestamp'].timestamp())}\"\n",
    "        \n",
    "        touchpoint = AttributionTouchpoint(\n",
    "            touchpoint_id=touchpoint_id,\n",
    "            user_id=user_id,\n",
    "            position_in_journey=i,\n",
    "            **data\n",
    "        )\n",
    "        \n",
    "        touchpoints.append(touchpoint)\n",
    "    \n",
    "    return touchpoints\n",
    "\n",
    "# Create sample touchpoints for attribution analysis\n",
    "touchpoint_data = [\n",
    "    {\n",
    "        \"channel\": \"google_ads\",\n",
    "        \"campaign\": \"brand_awareness\",\n",
    "        \"source\": \"google\",\n",
    "        \"medium\": \"cpc\",\n",
    "        \"content\": \"homepage_ad\",\n",
    "        \"timestamp\": datetime.now(timezone.utc) - timedelta(days=7)\n",
    "    },\n",
    "    {\n",
    "        \"channel\": \"email\",\n",
    "        \"campaign\": \"newsletter\",\n",
    "        \"source\": \"email\",\n",
    "        \"medium\": \"email\",\n",
    "        \"content\": \"welcome_series_2\",\n",
    "        \"timestamp\": datetime.now(timezone.utc) - timedelta(days=3)\n",
    "    },\n",
    "    {\n",
    "        \"channel\": \"organic_search\",\n",
    "        \"source\": \"google\",\n",
    "        \"medium\": \"organic\",\n",
    "        \"timestamp\": datetime.now(timezone.utc) - timedelta(days=1)\n",
    "    },\n",
    "    {\n",
    "        \"channel\": \"direct\",\n",
    "        \"source\": \"direct\",\n",
    "        \"medium\": \"none\",\n",
    "        \"timestamp\": datetime.now(timezone.utc),\n",
    "        \"conversion_value\": 49.99\n",
    "    }\n",
    "]\n",
    "\n",
    "user_touchpoints = create_attribution_touchpoints(\n",
    "    user_id=\"user_attribution_001\",\n",
    "    touchpoint_data=touchpoint_data\n",
    ")\n",
    "\n",
    "print(f\"Created {len(user_touchpoints)} attribution touchpoints:\")\n",
    "for tp in user_touchpoints:\n",
    "    print(f\"  {tp.position_in_journey}. {tp.channel} ({tp.source}/{tp.medium}) - {tp.timestamp.date()}\")\n",
    "    if tp.conversion_value:\n",
    "        print(f\"     Conversion Value: ${tp.conversion_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Calculate attribution weights\n",
    "def calculate_attribution_weights(\n",
    "    touchpoints: List[AttributionTouchpoint],\n",
    "    model: AttributionModel\n",
    ") -> List[float]:\n",
    "    \"\"\"Calculate attribution weights based on the specified model.\"\"\"\n",
    "    \n",
    "    num_touchpoints = len(touchpoints)\n",
    "    \n",
    "    if num_touchpoints == 0:\n",
    "        return []\n",
    "    \n",
    "    if num_touchpoints == 1:\n",
    "        return [1.0]\n",
    "    \n",
    "    if model == AttributionModel.FIRST_TOUCH:\n",
    "        weights = [1.0] + [0.0] * (num_touchpoints - 1)\n",
    "    \n",
    "    elif model == AttributionModel.LAST_TOUCH:\n",
    "        weights = [0.0] * (num_touchpoints - 1) + [1.0]\n",
    "    \n",
    "    elif model == AttributionModel.LINEAR:\n",
    "        weight = 1.0 / num_touchpoints\n",
    "        weights = [weight] * num_touchpoints\n",
    "    \n",
    "    elif model == AttributionModel.TIME_DECAY:\n",
    "        # More recent touchpoints get higher weights\n",
    "        base_weights = []\n",
    "        for i in range(num_touchpoints):\n",
    "            # Exponential decay with half-life\n",
    "            weight = 2 ** i  # More recent = higher weight\n",
    "            base_weights.append(weight)\n",
    "        \n",
    "        # Normalize to sum to 1.0\n",
    "        total_weight = sum(base_weights)\n",
    "        weights = [w / total_weight for w in base_weights]\n",
    "    \n",
    "    elif model == AttributionModel.POSITION_BASED:\n",
    "        # 40% first touch, 40% last touch, 20% middle touches\n",
    "        if num_touchpoints == 2:\n",
    "            weights = [0.5, 0.5]\n",
    "        else:\n",
    "            middle_weight = 0.2 / (num_touchpoints - 2) if num_touchpoints > 2 else 0\n",
    "            weights = [0.4] + [middle_weight] * (num_touchpoints - 2) + [0.4]\n",
    "    \n",
    "    else:\n",
    "        # Default to linear\n",
    "        weight = 1.0 / num_touchpoints\n",
    "        weights = [weight] * num_touchpoints\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Test different attribution models\n",
    "attribution_models = [\n",
    "    AttributionModel.FIRST_TOUCH,\n",
    "    AttributionModel.LAST_TOUCH,\n",
    "    AttributionModel.LINEAR,\n",
    "    AttributionModel.TIME_DECAY,\n",
    "    AttributionModel.POSITION_BASED\n",
    "]\n",
    "\n",
    "print(\"Attribution weight analysis:\")\n",
    "for model in attribution_models:\n",
    "    weights = calculate_attribution_weights(user_touchpoints, model)\n",
    "    print(f\"\\n{model.upper()}:\")\n",
    "    \n",
    "    for i, (tp, weight) in enumerate(zip(user_touchpoints, weights)):\n",
    "        print(f\"  {tp.channel}: {weight:.3f} ({weight*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"  Total weight: {sum(weights):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Create attribution analysis\n",
    "def create_attribution_analysis(\n",
    "    touchpoints: List[AttributionTouchpoint],\n",
    "    model: AttributionModel,\n",
    "    conversion_value: float\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create comprehensive attribution analysis.\"\"\"\n",
    "    \n",
    "    weights = calculate_attribution_weights(touchpoints, model)\n",
    "    \n",
    "    # Calculate attributed value for each touchpoint\n",
    "    channel_attribution = defaultdict(float)\n",
    "    campaign_attribution = defaultdict(float)\n",
    "    source_attribution = defaultdict(float)\n",
    "    \n",
    "    touchpoint_details = []\n",
    "    \n",
    "    for tp, weight in zip(touchpoints, weights):\n",
    "        attributed_value = conversion_value * weight\n",
    "        \n",
    "        channel_attribution[tp.channel] += attributed_value\n",
    "        if tp.campaign:\n",
    "            campaign_attribution[tp.campaign] += attributed_value\n",
    "        source_attribution[tp.source] += attributed_value\n",
    "        \n",
    "        touchpoint_details.append({\n",
    "            \"touchpoint_id\": tp.touchpoint_id,\n",
    "            \"position\": tp.position_in_journey,\n",
    "            \"channel\": tp.channel,\n",
    "            \"campaign\": tp.campaign,\n",
    "            \"source\": tp.source,\n",
    "            \"medium\": tp.medium,\n",
    "            \"timestamp\": tp.timestamp.isoformat(),\n",
    "            \"attribution_weight\": weight,\n",
    "            \"attributed_value\": attributed_value\n",
    "        })\n",
    "    \n",
    "    # Calculate journey metrics\n",
    "    journey_start = min(tp.timestamp for tp in touchpoints)\n",
    "    journey_end = max(tp.timestamp for tp in touchpoints)\n",
    "    journey_duration_days = (journey_end - journey_start).days\n",
    "    \n",
    "    analysis = {\n",
    "        \"attribution_model\": model,\n",
    "        \"total_conversion_value\": conversion_value,\n",
    "        \"total_touchpoints\": len(touchpoints),\n",
    "        \"journey_duration_days\": journey_duration_days,\n",
    "        \"journey_start\": journey_start.isoformat(),\n",
    "        \"journey_end\": journey_end.isoformat(),\n",
    "        \"channel_attribution\": dict(channel_attribution),\n",
    "        \"campaign_attribution\": dict(campaign_attribution),\n",
    "        \"source_attribution\": dict(source_attribution),\n",
    "        \"touchpoint_details\": touchpoint_details,\n",
    "        \"analyzed_at\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Create attribution analysis using time-decay model\n",
    "attribution_analysis = create_attribution_analysis(\n",
    "    touchpoints=user_touchpoints,\n",
    "    model=AttributionModel.TIME_DECAY,\n",
    "    conversion_value=49.99\n",
    ")\n",
    "\n",
    "print(\"Attribution analysis (Time Decay Model):\")\n",
    "print(json.dumps(attribution_analysis, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Event Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Analyze user behavior patterns\n",
    "def analyze_behavior_patterns(\n",
    "    user_journeys: List[UserJourney],\n",
    "    pattern_window_hours: int = 24\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Analyze common behavior patterns across user journeys.\"\"\"\n",
    "    \n",
    "    # Extract event sequences\n",
    "    event_sequences = []\n",
    "    stage_progressions = []\n",
    "    \n",
    "    for journey in user_journeys:\n",
    "        # Event sequence\n",
    "        events = [step.event for step in journey.steps]\n",
    "        event_sequences.append(events)\n",
    "        \n",
    "        # Stage progression\n",
    "        stages = [step.stage for step in journey.steps if step.stage]\n",
    "        if stages:\n",
    "            stage_progressions.append(stages)\n",
    "    \n",
    "    # Find common event patterns\n",
    "    event_pairs = defaultdict(int)\n",
    "    event_triplets = defaultdict(int)\n",
    "    \n",
    "    for sequence in event_sequences:\n",
    "        # Count event pairs\n",
    "        for i in range(len(sequence) - 1):\n",
    "            pair = (sequence[i], sequence[i + 1])\n",
    "            event_pairs[pair] += 1\n",
    "        \n",
    "        # Count event triplets\n",
    "        for i in range(len(sequence) - 2):\n",
    "            triplet = (sequence[i], sequence[i + 1], sequence[i + 2])\n",
    "            event_triplets[triplet] += 1\n",
    "    \n",
    "    # Find common stage progressions\n",
    "    stage_transitions = defaultdict(int)\n",
    "    \n",
    "    for progression in stage_progressions:\n",
    "        for i in range(len(progression) - 1):\n",
    "            transition = (progression[i], progression[i + 1])\n",
    "            stage_transitions[transition] += 1\n",
    "    \n",
    "    # Calculate journey metrics\n",
    "    total_journeys = len(user_journeys)\n",
    "    completed_journeys = sum(1 for j in user_journeys if j.is_completed)\n",
    "    avg_steps = statistics.mean(len(j.steps) for j in user_journeys) if user_journeys else 0\n",
    "    \n",
    "    durations = [j.get_duration_minutes() for j in user_journeys if j.get_duration_minutes()]\n",
    "    avg_duration = statistics.mean(durations) if durations else 0\n",
    "    \n",
    "    # Sort patterns by frequency\n",
    "    top_event_pairs = sorted(event_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    top_event_triplets = sorted(event_triplets.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_stage_transitions = sorted(stage_transitions.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    analysis = {\n",
    "        \"total_journeys\": total_journeys,\n",
    "        \"completed_journeys\": completed_journeys,\n",
    "        \"completion_rate\": completed_journeys / total_journeys if total_journeys > 0 else 0,\n",
    "        \"avg_steps_per_journey\": avg_steps,\n",
    "        \"avg_journey_duration_minutes\": avg_duration,\n",
    "        \"common_event_pairs\": [\n",
    "            {\"events\": list(pair), \"frequency\": count, \"percentage\": count/total_journeys*100}\n",
    "            for pair, count in top_event_pairs\n",
    "        ],\n",
    "        \"common_event_triplets\": [\n",
    "            {\"events\": list(triplet), \"frequency\": count, \"percentage\": count/total_journeys*100}\n",
    "            for triplet, count in top_event_triplets\n",
    "        ],\n",
    "        \"common_stage_transitions\": [\n",
    "            {\"transition\": list(transition), \"frequency\": count, \"percentage\": count/total_journeys*100}\n",
    "            for transition, count in top_stage_transitions\n",
    "        ],\n",
    "        \"analyzed_at\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze behavior patterns (using sample data)\n",
    "sample_journeys_for_analysis = [user_journey]  # In practice, use larger dataset\n",
    "\n",
    "behavior_analysis = analyze_behavior_patterns(sample_journeys_for_analysis)\n",
    "\n",
    "print(\"Behavior pattern analysis:\")\n",
    "print(json.dumps(behavior_analysis, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Event Data from Spark Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load advanced event data from Delta table\n",
    "print(\"=== Advanced Event Data Integration ===\")\n",
    "\n",
    "# Create sample advanced event data table if it doesn't exist\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{DATABASE_NAME}.user_journeys (\n",
    "    journey_id STRING,\n",
    "    user_id STRING,\n",
    "    journey_type STRING,\n",
    "    step_id STRING,\n",
    "    event_name STRING,\n",
    "    event_timestamp TIMESTAMP,\n",
    "    journey_stage STRING,\n",
    "    properties MAP<STRING, STRING>,\n",
    "    conversion_value DOUBLE,\n",
    "    session_id STRING\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample journey data\n",
    "spark.sql(f\"\"\"\n",
    "INSERT INTO {CATALOG_NAME}.{DATABASE_NAME}.user_journeys\n",
    "SELECT * FROM VALUES\n",
    "    ('journey_001', 'user_spark_advanced_001', 'onboarding', 'landing', 'Page Viewed', current_timestamp() - INTERVAL 10 MINUTES, 'awareness', map('page_name', 'Home', 'source', 'google'), 0.0, 'session_001'),\n",
    "    ('journey_001', 'user_spark_advanced_001', 'onboarding', 'signup_form', 'Form Viewed', current_timestamp() - INTERVAL 8 MINUTES, 'interest', map('form_name', 'registration'), 0.0, 'session_001'),\n",
    "    ('journey_001', 'user_spark_advanced_001', 'onboarding', 'registration', 'User Registered', current_timestamp() - INTERVAL 5 MINUTES, 'conversion', map('method', 'email'), 0.0, 'session_001'),\n",
    "    ('journey_002', 'user_spark_advanced_002', 'purchase', 'product_view', 'Product Viewed', current_timestamp() - INTERVAL 30 MINUTES, 'awareness', map('product_id', 'prod_123'), 0.0, 'session_002'),\n",
    "    ('journey_002', 'user_spark_advanced_002', 'purchase', 'add_to_cart', 'Product Added to Cart', current_timestamp() - INTERVAL 25 MINUTES, 'interest', map('product_id', 'prod_123'), 0.0, 'session_002'),\n",
    "    ('journey_002', 'user_spark_advanced_002', 'purchase', 'checkout', 'Checkout Started', current_timestamp() - INTERVAL 20 MINUTES, 'consideration', map('cart_value', '99.99'), 0.0, 'session_002'),\n",
    "    ('journey_002', 'user_spark_advanced_002', 'purchase', 'purchase', 'Order Completed', current_timestamp() - INTERVAL 15 MINUTES, 'conversion', map('order_value', '99.99'), 99.99, 'session_002')\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1 FROM {CATALOG_NAME}.{DATABASE_NAME}.user_journeys \n",
    "    WHERE journey_id = 'journey_001'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Load journey data\n",
    "journeys_df = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.user_journeys\")\n",
    "print(\"Sample user journey data from Spark:\")\n",
    "journeys_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Spark journey data to advanced events\n",
    "def transform_spark_journeys_to_events(df):\n",
    "    \"\"\"Transform journey data from Spark to Customer.IO advanced events.\"\"\"\n",
    "    \n",
    "    # Collect data (in production, process in batches)\n",
    "    journey_data = df.collect()\n",
    "    \n",
    "    # Group by journey\n",
    "    journeys_by_id = defaultdict(list)\n",
    "    for row in journey_data:\n",
    "        journeys_by_id[row['journey_id']].append(row)\n",
    "    \n",
    "    events = []\n",
    "    \n",
    "    for journey_id, steps in journeys_by_id.items():\n",
    "        # Sort steps by timestamp\n",
    "        steps.sort(key=lambda x: x['event_timestamp'])\n",
    "        \n",
    "        user_id = steps[0]['user_id']\n",
    "        journey_type = steps[0]['journey_type']\n",
    "        \n",
    "        # Create journey analysis event\n",
    "        journey_event = {\n",
    "            \"userId\": user_id,\n",
    "            \"event\": \"Advanced Journey Analyzed\",\n",
    "            \"properties\": {\n",
    "                \"journey_id\": journey_id,\n",
    "                \"journey_type\": journey_type,\n",
    "                \"total_steps\": len(steps),\n",
    "                \"journey_stages\": list(set(step['journey_stage'] for step in steps if step['journey_stage'])),\n",
    "                \"conversion_value\": max(step['conversion_value'] or 0 for step in steps),\n",
    "                \"session_id\": steps[0]['session_id'],\n",
    "                \"first_event\": steps[0]['event_name'],\n",
    "                \"last_event\": steps[-1]['event_name'],\n",
    "                \"journey_duration_minutes\": (\n",
    "                    steps[-1]['event_timestamp'] - steps[0]['event_timestamp']\n",
    "                ).total_seconds() / 60 if len(steps) > 1 else 0,\n",
    "                \"data_source\": \"spark_etl\",\n",
    "                \"analyzed_at\": datetime.now(timezone.utc).isoformat()\n",
    "            },\n",
    "            \"timestamp\": steps[-1]['event_timestamp']\n",
    "        }\n",
    "        \n",
    "        events.append(journey_event)\n",
    "        \n",
    "        # Create step sequence event\n",
    "        step_sequence_event = {\n",
    "            \"userId\": user_id,\n",
    "            \"event\": \"Journey Step Sequence\",\n",
    "            \"properties\": {\n",
    "                \"journey_id\": journey_id,\n",
    "                \"step_sequence\": [step['step_id'] for step in steps],\n",
    "                \"event_sequence\": [step['event_name'] for step in steps],\n",
    "                \"stage_sequence\": [step['journey_stage'] for step in steps if step['journey_stage']],\n",
    "                \"data_source\": \"spark_etl\",\n",
    "                \"analyzed_at\": datetime.now(timezone.utc).isoformat()\n",
    "            },\n",
    "            \"timestamp\": datetime.now(timezone.utc)\n",
    "        }\n",
    "        \n",
    "        events.append(step_sequence_event)\n",
    "    \n",
    "    return events\n",
    "\n",
    "# Transform journey data\n",
    "spark_journey_events = transform_spark_journeys_to_events(journeys_df)\n",
    "print(f\"Transformed {len(spark_journey_events)} advanced journey events\")\n",
    "\n",
    "# Show sample\n",
    "if spark_journey_events:\n",
    "    print(\"\\nSample advanced journey event:\")\n",
    "    print(json.dumps(spark_journey_events[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Event Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Real-time event pattern detection\n",
    "class RealTimePatternDetector:\n",
    "    \"\"\"Real-time pattern detection for event streams.\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size_minutes: int = 30):\n",
    "        self.window_size_minutes = window_size_minutes\n",
    "        self.event_windows = defaultdict(deque)  # user_id -> deque of events\n",
    "        self.pattern_alerts = []\n",
    "        \n",
    "    def add_event(\n",
    "        self, \n",
    "        user_id: str, \n",
    "        event_name: str, \n",
    "        timestamp: datetime,\n",
    "        properties: Dict[str, Any] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Add event to stream and detect patterns.\"\"\"\n",
    "        \n",
    "        properties = properties or {}\n",
    "        \n",
    "        # Add event to user's window\n",
    "        event = {\n",
    "            \"event_name\": event_name,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"properties\": properties\n",
    "        }\n",
    "        \n",
    "        self.event_windows[user_id].append(event)\n",
    "        \n",
    "        # Clean old events outside window\n",
    "        cutoff_time = timestamp - timedelta(minutes=self.window_size_minutes)\n",
    "        while (self.event_windows[user_id] and \n",
    "               self.event_windows[user_id][0][\"timestamp\"] < cutoff_time):\n",
    "            self.event_windows[user_id].popleft()\n",
    "        \n",
    "        # Detect patterns\n",
    "        patterns = self._detect_patterns(user_id)\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def _detect_patterns(self, user_id: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect behavioral patterns for a user.\"\"\"\n",
    "        \n",
    "        events = list(self.event_windows[user_id])\n",
    "        patterns = []\n",
    "        \n",
    "        if len(events) < 2:\n",
    "            return patterns\n",
    "        \n",
    "        # Pattern 1: Rapid engagement (multiple events in short time)\n",
    "        if len(events) >= 5:\n",
    "            recent_events = events[-5:]\n",
    "            time_span = (recent_events[-1][\"timestamp\"] - recent_events[0][\"timestamp\"]).total_seconds() / 60\n",
    "            \n",
    "            if time_span <= 5:  # 5 events in 5 minutes\n",
    "                patterns.append({\n",
    "                    \"pattern_type\": \"rapid_engagement\",\n",
    "                    \"user_id\": user_id,\n",
    "                    \"description\": \"User showing rapid engagement\",\n",
    "                    \"event_count\": len(recent_events),\n",
    "                    \"time_span_minutes\": time_span,\n",
    "                    \"detected_at\": datetime.now(timezone.utc)\n",
    "                })\n",
    "        \n",
    "        # Pattern 2: Abandonment risk (long gap between events)\n",
    "        if len(events) >= 2:\n",
    "            last_event_time = events[-1][\"timestamp\"]\n",
    "            current_time = datetime.now(timezone.utc)\n",
    "            gap_minutes = (current_time - last_event_time).total_seconds() / 60\n",
    "            \n",
    "            if gap_minutes >= 15:  # No activity for 15 minutes\n",
    "                patterns.append({\n",
    "                    \"pattern_type\": \"abandonment_risk\",\n",
    "                    \"user_id\": user_id,\n",
    "                    \"description\": \"User at risk of abandonment\",\n",
    "                    \"gap_minutes\": gap_minutes,\n",
    "                    \"last_event\": events[-1][\"event_name\"],\n",
    "                    \"detected_at\": datetime.now(timezone.utc)\n",
    "                })\n",
    "        \n",
    "        # Pattern 3: Conversion intent (specific event sequence)\n",
    "        event_names = [e[\"event_name\"] for e in events[-3:]]\n",
    "        conversion_sequences = [\n",
    "            [\"Product Viewed\", \"Product Added to Cart\", \"Checkout Started\"],\n",
    "            [\"Page Viewed\", \"Form Viewed\", \"Form Field Completed\"]\n",
    "        ]\n",
    "        \n",
    "        for sequence in conversion_sequences:\n",
    "            if event_names == sequence:\n",
    "                patterns.append({\n",
    "                    \"pattern_type\": \"conversion_intent\",\n",
    "                    \"user_id\": user_id,\n",
    "                    \"description\": f\"User showing conversion intent: {' -> '.join(sequence)}\",\n",
    "                    \"event_sequence\": sequence,\n",
    "                    \"detected_at\": datetime.now(timezone.utc)\n",
    "                })\n",
    "        \n",
    "        return patterns\n",
    "\n",
    "# Initialize real-time detector\n",
    "pattern_detector = RealTimePatternDetector(window_size_minutes=30)\n",
    "\n",
    "print(\"Real-time pattern detector initialized\")\n",
    "print(\"Window size: 30 minutes\")\n",
    "print(\"Pattern types: rapid_engagement, abandonment_risk, conversion_intent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test real-time pattern detection\n",
    "def simulate_real_time_events():\n",
    "    \"\"\"Simulate real-time event stream for pattern detection.\"\"\"\n",
    "    \n",
    "    base_time = datetime.now(timezone.utc)\n",
    "    all_patterns = []\n",
    "    \n",
    "    # Simulate rapid engagement pattern\n",
    "    print(\"Simulating rapid engagement pattern...\")\n",
    "    rapid_events = [\n",
    "        (\"Page Viewed\", {\"page_name\": \"Home\"}),\n",
    "        (\"Product Viewed\", {\"product_id\": \"prod_123\"}),\n",
    "        (\"Product Viewed\", {\"product_id\": \"prod_456\"}),\n",
    "        (\"Product Added to Cart\", {\"product_id\": \"prod_123\"}),\n",
    "        (\"Checkout Started\", {\"cart_value\": \"49.99\"})\n",
    "    ]\n",
    "    \n",
    "    for i, (event_name, properties) in enumerate(rapid_events):\n",
    "        timestamp = base_time + timedelta(minutes=i)  # 1 minute apart\n",
    "        patterns = pattern_detector.add_event(\n",
    "            user_id=\"user_rapid_001\",\n",
    "            event_name=event_name,\n",
    "            timestamp=timestamp,\n",
    "            properties=properties\n",
    "        )\n",
    "        all_patterns.extend(patterns)\n",
    "        \n",
    "        if patterns:\n",
    "            print(f\"  Pattern detected after '{event_name}': {patterns[-1]['pattern_type']}\")\n",
    "    \n",
    "    # Simulate conversion intent pattern\n",
    "    print(\"\\nSimulating conversion intent pattern...\")\n",
    "    conversion_events = [\n",
    "        (\"Product Viewed\", {\"product_id\": \"prod_789\"}),\n",
    "        (\"Product Added to Cart\", {\"product_id\": \"prod_789\"}),\n",
    "        (\"Checkout Started\", {\"cart_value\": \"99.99\"})\n",
    "    ]\n",
    "    \n",
    "    for i, (event_name, properties) in enumerate(conversion_events):\n",
    "        timestamp = base_time + timedelta(minutes=10 + i * 2)  # 2 minutes apart\n",
    "        patterns = pattern_detector.add_event(\n",
    "            user_id=\"user_conversion_001\",\n",
    "            event_name=event_name,\n",
    "            timestamp=timestamp,\n",
    "            properties=properties\n",
    "        )\n",
    "        all_patterns.extend(patterns)\n",
    "        \n",
    "        if patterns:\n",
    "            print(f\"  Pattern detected after '{event_name}': {patterns[-1]['pattern_type']}\")\n",
    "    \n",
    "    return all_patterns\n",
    "\n",
    "# Run simulation\n",
    "detected_patterns = simulate_real_time_events()\n",
    "\n",
    "print(f\"\\nTotal patterns detected: {len(detected_patterns)}\")\n",
    "for pattern in detected_patterns:\n",
    "    print(f\"\\nPattern: {pattern['pattern_type']}\")\n",
    "    print(f\"User: {pattern['user_id']}\")\n",
    "    print(f\"Description: {pattern['description']}\")\n",
    "    if 'event_sequence' in pattern:\n",
    "        print(f\"Sequence: {' -> '.join(pattern['event_sequence'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Advanced Events to Customer.IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Send advanced tracking events\n",
    "@retry_on_error(max_retries=3, backoff_factor=2.0)\n",
    "def send_advanced_events(\n",
    "    events: List[Dict[str, Any]],\n",
    "    test_mode: bool = True\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Send advanced tracking events in optimized batches.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create batch requests\n",
    "        batch_requests = [{\"type\": \"track\", **event} for event in events]\n",
    "        \n",
    "        # Optimize batch sizes\n",
    "        optimized_batches = BatchTransformer.optimize_batch_sizes(\n",
    "            requests=batch_requests,\n",
    "            max_size_bytes=500 * 1024  # 500KB limit\n",
    "        )\n",
    "        \n",
    "        print(f\"Optimized {len(events)} advanced events into {len(optimized_batches)} batch(es)\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Process each batch\n",
    "        for i, batch in enumerate(optimized_batches):\n",
    "            try:\n",
    "                if test_mode:\n",
    "                    print(f\"  Batch {i+1}: {len(batch)} events (test mode)\")\n",
    "                    results.append({\n",
    "                        \"batch_id\": i,\n",
    "                        \"status\": \"test_success\",\n",
    "                        \"count\": len(batch)\n",
    "                    })\n",
    "                else:\n",
    "                    response = client.batch(batch)\n",
    "                    results.append({\n",
    "                        \"batch_id\": i,\n",
    "                        \"status\": \"success\",\n",
    "                        \"count\": len(batch),\n",
    "                        \"response\": response\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"batch_id\": i,\n",
    "                    \"status\": \"failed\",\n",
    "                    \"count\": len(batch),\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                logger.error(f\"Advanced events batch {i} failed\", error=str(e))\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(\"Advanced events batch processing failed\", error=str(e))\n",
    "        raise\n",
    "\n",
    "# Combine all advanced events for sending\n",
    "all_advanced_events = []\n",
    "\n",
    "# Add journey completion event\n",
    "all_advanced_events.append(journey_completion)\n",
    "\n",
    "# Add pattern detection events\n",
    "for pattern in detected_patterns:\n",
    "    pattern_event = {\n",
    "        \"userId\": pattern[\"user_id\"],\n",
    "        \"event\": \"Behavioral Pattern Detected\",\n",
    "        \"properties\": {\n",
    "            \"pattern_type\": pattern[\"pattern_type\"],\n",
    "            \"description\": pattern[\"description\"],\n",
    "            \"detection_timestamp\": pattern[\"detected_at\"].isoformat(),\n",
    "            **{k: v for k, v in pattern.items() if k not in [\"user_id\", \"pattern_type\", \"description\", \"detected_at\"]}\n",
    "        },\n",
    "        \"timestamp\": pattern[\"detected_at\"]\n",
    "    }\n",
    "    all_advanced_events.append(pattern_event)\n",
    "\n",
    "# Add Spark journey events\n",
    "all_advanced_events.extend(spark_journey_events)\n",
    "\n",
    "# Send advanced events\n",
    "if all_advanced_events:\n",
    "    batch_results = send_advanced_events(\n",
    "        events=all_advanced_events,\n",
    "        test_mode=(ENVIRONMENT == \"test\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAdvanced events batch results:\")\n",
    "    for result in batch_results:\n",
    "        print(f\"  Batch {result['batch_id']}: {result['status']} ({result['count']} events)\")\n",
    "        if 'error' in result:\n",
    "            print(f\"    Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"No advanced events to send\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Monitoring and Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation: Advanced tracking performance metrics\n",
    "def calculate_advanced_tracking_metrics() -> Dict[str, Any]:\n",
    "    \"\"\"Calculate comprehensive advanced tracking performance metrics.\"\"\"\n",
    "    \n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    \n",
    "    metrics = {\n",
    "        \"journey_analytics\": {\n",
    "            \"total_journeys_analyzed\": 1,  # Sample data\n",
    "            \"avg_journey_duration_minutes\": user_journey.get_duration_minutes() or 0,\n",
    "            \"avg_steps_per_journey\": len(user_journey.steps),\n",
    "            \"completion_rate\": 1.0 if user_journey.is_completed else 0.0,\n",
    "            \"conversion_value_total\": user_journey.conversion_value or 0\n",
    "        },\n",
    "        \"funnel_analytics\": {\n",
    "            \"funnels_configured\": 1,\n",
    "            \"funnel_steps_total\": len(onboarding_funnel.steps),\n",
    "            \"attribution_models_used\": [AttributionModel.TIME_DECAY],\n",
    "            \"overall_conversion_rate\": funnel_analysis.get(\"overall_conversion_rate\", 0)\n",
    "        },\n",
    "        \"attribution_analytics\": {\n",
    "            \"touchpoints_analyzed\": len(user_touchpoints),\n",
    "            \"unique_channels\": len(set(tp.channel for tp in user_touchpoints)),\n",
    "            \"journey_duration_days\": attribution_analysis.get(\"journey_duration_days\", 0),\n",
    "            \"total_attributed_value\": attribution_analysis.get(\"total_conversion_value\", 0)\n",
    "        },\n",
    "        \"real_time_analytics\": {\n",
    "            \"patterns_detected\": len(detected_patterns),\n",
    "            \"pattern_types\": list(set(p[\"pattern_type\"] for p in detected_patterns)),\n",
    "            \"active_users_monitored\": len(pattern_detector.event_windows),\n",
    "            \"detection_window_minutes\": pattern_detector.window_size_minutes\n",
    "        },\n",
    "        \"data_processing\": {\n",
    "            \"spark_journeys_processed\": len(spark_journey_events) // 2,  # 2 events per journey\n",
    "            \"events_sent_total\": len(all_advanced_events),\n",
    "            \"batch_processing_efficiency\": (\n",
    "                sum(1 for r in batch_results if r[\"status\"] in [\"success\", \"test_success\"]) / \n",
    "                len(batch_results) if batch_results else 0\n",
    "            )\n",
    "        },\n",
    "        \"performance_metrics\": {\n",
    "            \"avg_event_processing_time_ms\": 50,  # Estimated\n",
    "            \"pattern_detection_latency_ms\": 25,  # Estimated\n",
    "            \"funnel_analysis_time_ms\": 100,  # Estimated\n",
    "            \"attribution_calculation_time_ms\": 75  # Estimated\n",
    "        },\n",
    "        \"system_health\": {\n",
    "            \"api_client_status\": \"healthy\",\n",
    "            \"event_manager_status\": \"healthy\",\n",
    "            \"pattern_detector_status\": \"healthy\",\n",
    "            \"last_health_check\": current_time.isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate and display metrics\n",
    "advanced_metrics = calculate_advanced_tracking_metrics()\n",
    "\n",
    "print(\"=== Advanced Tracking Performance Metrics ===\")\n",
    "print(json.dumps(advanced_metrics, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== Advanced Tracking Summary ===\")\n",
    "\n",
    "print(\"\\n=== User Journey Analysis ====\")\n",
    "print(\"SUCCESS: User journey tracking with multi-stage progression\")\n",
    "print(\"SUCCESS: Journey completion events with conversion values\")\n",
    "print(\"SUCCESS: Step-by-step duration and progression analysis\")\n",
    "print(\"SUCCESS: Journey metadata and context tracking\")\n",
    "\n",
    "print(\"\\n=== Conversion Funnel Analytics ====\")\n",
    "print(\"SUCCESS: Multi-step funnel configuration and analysis\")\n",
    "print(\"SUCCESS: Conversion rate calculation at each step\")\n",
    "print(\"SUCCESS: Drop-off analysis and optimization insights\")\n",
    "print(\"SUCCESS: Time-window based funnel progression\")\n",
    "\n",
    "print(\"\\n=== Attribution Modeling ====\")\n",
    "print(\"SUCCESS: Multi-touch attribution across channels\")\n",
    "print(\"SUCCESS: Multiple attribution models (first-touch, last-touch, linear, time-decay, position-based)\")\n",
    "print(\"SUCCESS: Attribution value distribution across touchpoints\")\n",
    "print(\"SUCCESS: Cross-channel journey analysis\")\n",
    "\n",
    "print(\"\\n=== Behavioral Pattern Detection ====\")\n",
    "print(\"SUCCESS: Real-time pattern detection with configurable windows\")\n",
    "print(\"SUCCESS: Rapid engagement pattern identification\")\n",
    "print(\"SUCCESS: Abandonment risk detection\")\n",
    "print(\"SUCCESS: Conversion intent pattern recognition\")\n",
    "\n",
    "print(\"\\n=== Advanced Analytics ====\")\n",
    "print(\"SUCCESS: Event sequence and pattern analysis\")\n",
    "print(\"SUCCESS: Stage progression tracking\")\n",
    "print(\"SUCCESS: Behavioral segmentation insights\")\n",
    "print(\"SUCCESS: Cross-platform journey unification\")\n",
    "\n",
    "print(\"\\n=== Data Integration ====\")\n",
    "print(\"SUCCESS: Spark DataFrame integration for journey data\")\n",
    "print(\"SUCCESS: Batch processing with size optimization\")\n",
    "print(\"SUCCESS: Real-time stream processing capabilities\")\n",
    "print(\"SUCCESS: Advanced event transformation and enrichment\")\n",
    "\n",
    "print(\"\\n=== Key Capabilities Demonstrated ====\")\n",
    "print(\"SUCCESS: Type-safe advanced tracking models with comprehensive validation\")\n",
    "print(\"SUCCESS: Multi-dimensional user journey analysis\")\n",
    "print(\"SUCCESS: Sophisticated conversion funnel analytics\")\n",
    "print(\"SUCCESS: Advanced attribution modeling with multiple touchpoint support\")\n",
    "print(\"SUCCESS: Real-time behavioral pattern detection\")\n",
    "print(\"SUCCESS: Performance monitoring and health checks\")\n",
    "print(\"SUCCESS: Seamless integration with existing EventManager infrastructure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the API client connection\n",
    "client.close()\n",
    "print(\"SUCCESS: API client connection closed\")\n",
    "\n",
    "print(\"\\nCOMPLETED: Advanced tracking notebook finished successfully!\")\n",
    "print(\"Ready for specialized ecommerce event tracking in the next notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}