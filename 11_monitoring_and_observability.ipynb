{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer.IO Monitoring and Observability\n",
    "\n",
    "Comprehensive monitoring, logging, and observability solutions for Customer.IO data pipelines including:\n",
    "- Real-time metrics collection and alerting\n",
    "- Application performance monitoring (APM)\n",
    "- Distributed tracing and correlation\n",
    "- Health checks and system monitoring\n",
    "- Log aggregation and analysis\n",
    "- Custom dashboard creation\n",
    "- Anomaly detection and alerting\n",
    "- Service level objectives (SLO) tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for monitoring and observability\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Dict, List, Optional, Any, Union, Callable, Set\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict, deque\n",
    "from enum import Enum\n",
    "import structlog\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import statistics\n",
    "import uuid\n",
    "import psutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import asyncio\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"SUCCESS: Core monitoring imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Customer.IO utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add utils to path for imports\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "\n",
    "from api_client import CustomerIOClient\n",
    "from error_handlers import retry_on_error, ErrorContext, CustomerIOError\n",
    "from validators import validate_request_size\n",
    "\n",
    "print(\"SUCCESS: Customer.IO utilities imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Monitoring Models\n",
    "\n",
    "Type-safe models for metrics, alerts, and monitoring configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricType(str, Enum):\n",
    "    \"\"\"Types of metrics that can be collected.\"\"\"\n",
    "    COUNTER = \"counter\"\n",
    "    GAUGE = \"gauge\"\n",
    "    HISTOGRAM = \"histogram\"\n",
    "    SUMMARY = \"summary\"\n",
    "    TIMER = \"timer\"\n",
    "\n",
    "class AlertSeverity(str, Enum):\n",
    "    \"\"\"Alert severity levels.\"\"\"\n",
    "    CRITICAL = \"critical\"\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "    INFO = \"info\"\n",
    "\n",
    "class HealthStatus(str, Enum):\n",
    "    \"\"\"Health check status values.\"\"\"\n",
    "    HEALTHY = \"healthy\"\n",
    "    DEGRADED = \"degraded\"\n",
    "    UNHEALTHY = \"unhealthy\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class TraceStatus(str, Enum):\n",
    "    \"\"\"Distributed tracing status.\"\"\"\n",
    "    SUCCESS = \"success\"\n",
    "    ERROR = \"error\"\n",
    "    TIMEOUT = \"timeout\"\n",
    "    CANCELLED = \"cancelled\"\n",
    "\n",
    "print(\"SUCCESS: Core monitoring enums defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(BaseModel):\n",
    "    \"\"\"Type-safe metric model.\"\"\"\n",
    "    name: str = Field(..., description=\"Metric name\")\n",
    "    type: MetricType = Field(..., description=\"Metric type\")\n",
    "    value: float = Field(..., description=\"Metric value\")\n",
    "    unit: Optional[str] = Field(None, description=\"Metric unit\")\n",
    "    tags: Dict[str, str] = Field(default_factory=dict, description=\"Metric tags\")\n",
    "    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    source: str = Field(..., description=\"Metric source\")\n",
    "    \n",
    "    @validator('name')\n",
    "    def validate_name(cls, v: str) -> str:\n",
    "        \"\"\"Validate metric name format.\"\"\"\n",
    "        if not v or len(v.strip()) == 0:\n",
    "            raise ValueError(\"Metric name cannot be empty\")\n",
    "        # Ensure metric name follows common conventions\n",
    "        if not v.replace('_', '').replace('.', '').replace('-', '').isalnum():\n",
    "            raise ValueError(\"Metric name must contain only alphanumeric, underscore, dot, or dash characters\")\n",
    "        return v.strip()\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "class Alert(BaseModel):\n",
    "    \"\"\"Type-safe alert model.\"\"\"\n",
    "    alert_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    name: str = Field(..., description=\"Alert name\")\n",
    "    severity: AlertSeverity = Field(..., description=\"Alert severity\")\n",
    "    message: str = Field(..., description=\"Alert message\")\n",
    "    source: str = Field(..., description=\"Alert source\")\n",
    "    metric_name: Optional[str] = Field(None, description=\"Related metric\")\n",
    "    threshold_value: Optional[float] = Field(None, description=\"Threshold value\")\n",
    "    current_value: Optional[float] = Field(None, description=\"Current value\")\n",
    "    tags: Dict[str, str] = Field(default_factory=dict, description=\"Alert tags\")\n",
    "    triggered_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    resolved_at: Optional[datetime] = Field(None, description=\"Resolution timestamp\")\n",
    "    \n",
    "    def is_resolved(self) -> bool:\n",
    "        \"\"\"Check if alert is resolved.\"\"\"\n",
    "        return self.resolved_at is not None\n",
    "    \n",
    "    def resolve(self) -> None:\n",
    "        \"\"\"Mark alert as resolved.\"\"\"\n",
    "        self.resolved_at = datetime.now(timezone.utc)\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: Core metric and alert models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthCheck(BaseModel):\n",
    "    \"\"\"Type-safe health check model.\"\"\"\n",
    "    check_id: str = Field(..., description=\"Health check identifier\")\n",
    "    name: str = Field(..., description=\"Check name\")\n",
    "    status: HealthStatus = Field(..., description=\"Check status\")\n",
    "    response_time_ms: float = Field(..., ge=0, description=\"Response time in milliseconds\")\n",
    "    details: Dict[str, Any] = Field(default_factory=dict, description=\"Check details\")\n",
    "    last_success: Optional[datetime] = Field(None, description=\"Last successful check\")\n",
    "    last_failure: Optional[datetime] = Field(None, description=\"Last failed check\")\n",
    "    consecutive_failures: int = Field(default=0, ge=0, description=\"Consecutive failure count\")\n",
    "    checked_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    \n",
    "    def is_healthy(self) -> bool:\n",
    "        \"\"\"Check if health check is passing.\"\"\"\n",
    "        return self.status == HealthStatus.HEALTHY\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "class TraceSpan(BaseModel):\n",
    "    \"\"\"Type-safe distributed tracing span model.\"\"\"\n",
    "    trace_id: str = Field(..., description=\"Trace identifier\")\n",
    "    span_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    parent_span_id: Optional[str] = Field(None, description=\"Parent span identifier\")\n",
    "    operation_name: str = Field(..., description=\"Operation name\")\n",
    "    service_name: str = Field(..., description=\"Service name\")\n",
    "    start_time: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    end_time: Optional[datetime] = Field(None, description=\"End timestamp\")\n",
    "    duration_ms: Optional[float] = Field(None, ge=0, description=\"Duration in milliseconds\")\n",
    "    status: TraceStatus = Field(default=TraceStatus.SUCCESS, description=\"Trace status\")\n",
    "    tags: Dict[str, str] = Field(default_factory=dict, description=\"Span tags\")\n",
    "    logs: List[Dict[str, Any]] = Field(default_factory=list, description=\"Span logs\")\n",
    "    \n",
    "    def finish(self, status: TraceStatus = TraceStatus.SUCCESS) -> None:\n",
    "        \"\"\"Finish the span.\"\"\"\n",
    "        self.end_time = datetime.now(timezone.utc)\n",
    "        self.duration_ms = (self.end_time - self.start_time).total_seconds() * 1000\n",
    "        self.status = status\n",
    "    \n",
    "    def add_log(self, level: str, message: str, **kwargs) -> None:\n",
    "        \"\"\"Add log entry to span.\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"level\": level,\n",
    "            \"message\": message,\n",
    "            **kwargs\n",
    "        }\n",
    "        self.logs.append(log_entry)\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "print(\"SUCCESS: Health check and tracing models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Collection System\n",
    "\n",
    "High-performance metrics collection with aggregation and buffering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCollector:\n",
    "    \"\"\"High-performance metrics collection system.\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size: int = 10000, flush_interval_seconds: int = 60):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.flush_interval = flush_interval_seconds\n",
    "        self.metrics_buffer = deque(maxlen=buffer_size)\n",
    "        self.aggregated_metrics = defaultdict(list)\n",
    "        self.last_flush = datetime.now(timezone.utc)\n",
    "        self.lock = threading.Lock()\n",
    "        self.logger = structlog.get_logger(\"metrics_collector\")\n",
    "        \n",
    "        # Start background flush thread\n",
    "        self._start_flush_thread()\n",
    "    \n",
    "    def record_metric(self, metric: Metric) -> None:\n",
    "        \"\"\"Record a metric with thread-safe buffering.\"\"\"\n",
    "        with self.lock:\n",
    "            self.metrics_buffer.append(metric)\n",
    "            \n",
    "            # Aggregate metrics by name for statistics\n",
    "            key = f\"{metric.name}:{metric.type}\"\n",
    "            self.aggregated_metrics[key].append(metric.value)\n",
    "            \n",
    "            # Keep only recent values for aggregation\n",
    "            if len(self.aggregated_metrics[key]) > 1000:\n",
    "                self.aggregated_metrics[key] = self.aggregated_metrics[key][-500:]\n",
    "    \n",
    "    def record_counter(self, name: str, value: float = 1, tags: Optional[Dict[str, str]] = None, source: str = \"default\") -> None:\n",
    "        \"\"\"Record a counter metric.\"\"\"\n",
    "        metric = Metric(\n",
    "            name=name,\n",
    "            type=MetricType.COUNTER,\n",
    "            value=value,\n",
    "            tags=tags or {},\n",
    "            source=source\n",
    "        )\n",
    "        self.record_metric(metric)\n",
    "    \n",
    "    def record_gauge(self, name: str, value: float, unit: Optional[str] = None, tags: Optional[Dict[str, str]] = None, source: str = \"default\") -> None:\n",
    "        \"\"\"Record a gauge metric.\"\"\"\n",
    "        metric = Metric(\n",
    "            name=name,\n",
    "            type=MetricType.GAUGE,\n",
    "            value=value,\n",
    "            unit=unit,\n",
    "            tags=tags or {},\n",
    "            source=source\n",
    "        )\n",
    "        self.record_metric(metric)\n",
    "    \n",
    "    def record_timer(self, name: str, duration_ms: float, tags: Optional[Dict[str, str]] = None, source: str = \"default\") -> None:\n",
    "        \"\"\"Record a timer metric.\"\"\"\n",
    "        metric = Metric(\n",
    "            name=name,\n",
    "            type=MetricType.TIMER,\n",
    "            value=duration_ms,\n",
    "            unit=\"ms\",\n",
    "            tags=tags or {},\n",
    "            source=source\n",
    "        )\n",
    "        self.record_metric(metric)\n",
    "    \n",
    "    def get_metric_statistics(self, metric_name: str, metric_type: MetricType) -> Dict[str, float]:\n",
    "        \"\"\"Get statistics for a specific metric.\"\"\"\n",
    "        key = f\"{metric_name}:{metric_type}\"\n",
    "        values = self.aggregated_metrics.get(key, [])\n",
    "        \n",
    "        if not values:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            \"count\": len(values),\n",
    "            \"sum\": sum(values),\n",
    "            \"mean\": statistics.mean(values),\n",
    "            \"median\": statistics.median(values),\n",
    "            \"min\": min(values),\n",
    "            \"max\": max(values),\n",
    "            \"std_dev\": statistics.stdev(values) if len(values) > 1 else 0,\n",
    "            \"p95\": statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),\n",
    "            \"p99\": statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)\n",
    "        }\n",
    "    \n",
    "    def get_buffer_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get metrics buffer status.\"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                \"buffer_size\": len(self.metrics_buffer),\n",
    "                \"buffer_capacity\": self.buffer_size,\n",
    "                \"buffer_utilization\": len(self.metrics_buffer) / self.buffer_size * 100,\n",
    "                \"aggregated_metric_types\": len(self.aggregated_metrics),\n",
    "                \"last_flush\": self.last_flush.isoformat(),\n",
    "                \"flush_interval_seconds\": self.flush_interval\n",
    "            }\n",
    "    \n",
    "    def flush_metrics(self) -> List[Metric]:\n",
    "        \"\"\"Flush metrics buffer and return metrics.\"\"\"\n",
    "        with self.lock:\n",
    "            metrics = list(self.metrics_buffer)\n",
    "            self.metrics_buffer.clear()\n",
    "            self.last_flush = datetime.now(timezone.utc)\n",
    "            \n",
    "            self.logger.info(\n",
    "                \"Metrics flushed\",\n",
    "                count=len(metrics),\n",
    "                aggregated_types=len(self.aggregated_metrics)\n",
    "            )\n",
    "            \n",
    "            return metrics\n",
    "    \n",
    "    def _start_flush_thread(self) -> None:\n",
    "        \"\"\"Start background thread for periodic flushing.\"\"\"\n",
    "        def flush_worker():\n",
    "            while True:\n",
    "                time.sleep(self.flush_interval)\n",
    "                try:\n",
    "                    self.flush_metrics()\n",
    "                except Exception as e:\n",
    "                    self.logger.error(\"Metrics flush failed\", error=str(e))\n",
    "        \n",
    "        thread = threading.Thread(target=flush_worker, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "print(\"SUCCESS: MetricsCollector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alerting System\n",
    "\n",
    "Intelligent alerting with threshold management and notification routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertRule(BaseModel):\n",
    "    \"\"\"Type-safe alert rule definition.\"\"\"\n",
    "    rule_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    name: str = Field(..., description=\"Rule name\")\n",
    "    metric_name: str = Field(..., description=\"Metric to monitor\")\n",
    "    condition: str = Field(..., description=\"Alert condition (>, <, >=, <=, ==, !=)\")\n",
    "    threshold: float = Field(..., description=\"Threshold value\")\n",
    "    severity: AlertSeverity = Field(..., description=\"Alert severity\")\n",
    "    window_minutes: int = Field(default=5, gt=0, description=\"Evaluation window\")\n",
    "    consecutive_violations: int = Field(default=1, gt=0, description=\"Required consecutive violations\")\n",
    "    enabled: bool = Field(default=True, description=\"Rule enabled status\")\n",
    "    tags: Dict[str, str] = Field(default_factory=dict, description=\"Rule tags\")\n",
    "    \n",
    "    def evaluate(self, current_value: float) -> bool:\n",
    "        \"\"\"Evaluate if current value violates the rule.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return False\n",
    "        \n",
    "        if self.condition == \">\":\n",
    "            return current_value > self.threshold\n",
    "        elif self.condition == \"<\":\n",
    "            return current_value < self.threshold\n",
    "        elif self.condition == \">=\":\n",
    "            return current_value >= self.threshold\n",
    "        elif self.condition == \"<=\":\n",
    "            return current_value <= self.threshold\n",
    "        elif self.condition == \"==\":\n",
    "            return current_value == self.threshold\n",
    "        elif self.condition == \"!=\":\n",
    "            return current_value != self.threshold\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        use_enum_values = True\n",
    "        validate_assignment = True\n",
    "\n",
    "class AlertManager:\n",
    "    \"\"\"Intelligent alerting system with threshold management.\"\"\"\n",
    "    \n",
    "    def __init__(self, metrics_collector: MetricsCollector):\n",
    "        self.metrics_collector = metrics_collector\n",
    "        self.rules: Dict[str, AlertRule] = {}\n",
    "        self.active_alerts: Dict[str, Alert] = {}\n",
    "        self.alert_history: List[Alert] = []\n",
    "        self.rule_violations: Dict[str, List[datetime]] = defaultdict(list)\n",
    "        self.logger = structlog.get_logger(\"alert_manager\")\n",
    "        \n",
    "        # Start alert evaluation thread\n",
    "        self._start_evaluation_thread()\n",
    "    \n",
    "    def add_rule(self, rule: AlertRule) -> None:\n",
    "        \"\"\"Add alert rule.\"\"\"\n",
    "        self.rules[rule.rule_id] = rule\n",
    "        self.logger.info(\n",
    "            \"Alert rule added\",\n",
    "            rule_id=rule.rule_id,\n",
    "            name=rule.name,\n",
    "            metric=rule.metric_name\n",
    "        )\n",
    "    \n",
    "    def remove_rule(self, rule_id: str) -> bool:\n",
    "        \"\"\"Remove alert rule.\"\"\"\n",
    "        if rule_id in self.rules:\n",
    "            del self.rules[rule_id]\n",
    "            # Clean up any violations for this rule\n",
    "            if rule_id in self.rule_violations:\n",
    "                del self.rule_violations[rule_id]\n",
    "            self.logger.info(\"Alert rule removed\", rule_id=rule_id)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def evaluate_rules(self) -> List[Alert]:\n",
    "        \"\"\"Evaluate all alert rules against current metrics.\"\"\"\n",
    "        new_alerts = []\n",
    "        current_time = datetime.now(timezone.utc)\n",
    "        \n",
    "        for rule in self.rules.values():\n",
    "            if not rule.enabled:\n",
    "                continue\n",
    "            \n",
    "            # Get recent metric statistics\n",
    "            stats = self.metrics_collector.get_metric_statistics(\n",
    "                rule.metric_name,\n",
    "                MetricType.GAUGE  # Assume gauge for simplicity\n",
    "            )\n",
    "            \n",
    "            if not stats:\n",
    "                continue\n",
    "            \n",
    "            current_value = stats.get(\"mean\", 0)  # Use mean value for evaluation\n",
    "            \n",
    "            # Check if rule is violated\n",
    "            if rule.evaluate(current_value):\n",
    "                # Record violation\n",
    "                self.rule_violations[rule.rule_id].append(current_time)\n",
    "                \n",
    "                # Clean old violations outside window\n",
    "                window_start = current_time - timedelta(minutes=rule.window_minutes)\n",
    "                self.rule_violations[rule.rule_id] = [\n",
    "                    v for v in self.rule_violations[rule.rule_id]\n",
    "                    if v >= window_start\n",
    "                ]\n",
    "                \n",
    "                # Check if we have enough consecutive violations\n",
    "                if len(self.rule_violations[rule.rule_id]) >= rule.consecutive_violations:\n",
    "                    # Check if alert already exists\n",
    "                    alert_key = f\"{rule.rule_id}:{rule.metric_name}\"\n",
    "                    if alert_key not in self.active_alerts:\n",
    "                        # Create new alert\n",
    "                        alert = Alert(\n",
    "                            name=rule.name,\n",
    "                            severity=rule.severity,\n",
    "                            message=f\"Metric {rule.metric_name} {rule.condition} {rule.threshold} (current: {current_value:.2f})\",\n",
    "                            source=\"alert_manager\",\n",
    "                            metric_name=rule.metric_name,\n",
    "                            threshold_value=rule.threshold,\n",
    "                            current_value=current_value,\n",
    "                            tags=rule.tags\n",
    "                        )\n",
    "                        \n",
    "                        self.active_alerts[alert_key] = alert\n",
    "                        self.alert_history.append(alert)\n",
    "                        new_alerts.append(alert)\n",
    "                        \n",
    "                        self.logger.warning(\n",
    "                            \"Alert triggered\",\n",
    "                            alert_id=alert.alert_id,\n",
    "                            rule_name=rule.name,\n",
    "                            current_value=current_value,\n",
    "                            threshold=rule.threshold\n",
    "                        )\n",
    "            else:\n",
    "                # Rule not violated, check if we should resolve alert\n",
    "                alert_key = f\"{rule.rule_id}:{rule.metric_name}\"\n",
    "                if alert_key in self.active_alerts:\n",
    "                    alert = self.active_alerts[alert_key]\n",
    "                    alert.resolve()\n",
    "                    del self.active_alerts[alert_key]\n",
    "                    \n",
    "                    self.logger.info(\n",
    "                        \"Alert resolved\",\n",
    "                        alert_id=alert.alert_id,\n",
    "                        rule_name=rule.name,\n",
    "                        current_value=current_value\n",
    "                    )\n",
    "                \n",
    "                # Clear violations for this rule\n",
    "                if rule.rule_id in self.rule_violations:\n",
    "                    self.rule_violations[rule.rule_id].clear()\n",
    "        \n",
    "        return new_alerts\n",
    "    \n",
    "    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> List[Alert]:\n",
    "        \"\"\"Get currently active alerts.\"\"\"\n",
    "        alerts = list(self.active_alerts.values())\n",
    "        if severity:\n",
    "            alerts = [alert for alert in alerts if alert.severity == severity]\n",
    "        return alerts\n",
    "    \n",
    "    def get_alert_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get alerting system statistics.\"\"\"\n",
    "        now = datetime.now(timezone.utc)\n",
    "        last_24h = now - timedelta(hours=24)\n",
    "        \n",
    "        recent_alerts = [\n",
    "            alert for alert in self.alert_history\n",
    "            if alert.triggered_at >= last_24h\n",
    "        ]\n",
    "        \n",
    "        severity_counts = defaultdict(int)\n",
    "        for alert in recent_alerts:\n",
    "            severity_counts[alert.severity] += 1\n",
    "        \n",
    "        return {\n",
    "            \"total_rules\": len(self.rules),\n",
    "            \"enabled_rules\": len([r for r in self.rules.values() if r.enabled]),\n",
    "            \"active_alerts\": len(self.active_alerts),\n",
    "            \"alerts_last_24h\": len(recent_alerts),\n",
    "            \"severity_distribution\": dict(severity_counts),\n",
    "            \"total_alert_history\": len(self.alert_history)\n",
    "        }\n",
    "    \n",
    "    def _start_evaluation_thread(self) -> None:\n",
    "        \"\"\"Start background thread for rule evaluation.\"\"\"\n",
    "        def evaluation_worker():\n",
    "            while True:\n",
    "                time.sleep(30)  # Evaluate every 30 seconds\n",
    "                try:\n",
    "                    self.evaluate_rules()\n",
    "                except Exception as e:\n",
    "                    self.logger.error(\"Alert evaluation failed\", error=str(e))\n",
    "        \n",
    "        thread = threading.Thread(target=evaluation_worker, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "print(\"SUCCESS: AlertManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Monitoring System\n",
    "\n",
    "Comprehensive health checks for services and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthMonitor:\n",
    "    \"\"\"Comprehensive health monitoring system.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: CustomerIOClient):\n",
    "        self.client = client\n",
    "        self.health_checks: Dict[str, HealthCheck] = {}\n",
    "        self.check_functions: Dict[str, Callable[[], Dict[str, Any]]] = {}\n",
    "        self.logger = structlog.get_logger(\"health_monitor\")\n",
    "        \n",
    "        # Register default health checks\n",
    "        self._register_default_checks()\n",
    "        \n",
    "        # Start periodic health checking\n",
    "        self._start_health_check_thread()\n",
    "    \n",
    "    def register_check(self, check_id: str, name: str, check_function: Callable[[], Dict[str, Any]]) -> None:\n",
    "        \"\"\"Register a custom health check.\"\"\"\n",
    "        self.check_functions[check_id] = check_function\n",
    "        self.logger.info(\"Health check registered\", check_id=check_id, name=name)\n",
    "    \n",
    "    def run_check(self, check_id: str) -> HealthCheck:\n",
    "        \"\"\"Run a specific health check.\"\"\"\n",
    "        if check_id not in self.check_functions:\n",
    "            raise ValueError(f\"Health check {check_id} not found\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = self.check_functions[check_id]()\n",
    "            response_time = (time.time() - start_time) * 1000\n",
    "            \n",
    "            health_check = HealthCheck(\n",
    "                check_id=check_id,\n",
    "                name=result.get(\"name\", check_id),\n",
    "                status=HealthStatus(result.get(\"status\", HealthStatus.UNKNOWN)),\n",
    "                response_time_ms=response_time,\n",
    "                details=result.get(\"details\", {})\n",
    "            )\n",
    "            \n",
    "            # Update success/failure tracking\n",
    "            if health_check.is_healthy():\n",
    "                health_check.last_success = health_check.checked_at\n",
    "                if check_id in self.health_checks:\n",
    "                    self.health_checks[check_id].consecutive_failures = 0\n",
    "            else:\n",
    "                health_check.last_failure = health_check.checked_at\n",
    "                if check_id in self.health_checks:\n",
    "                    health_check.consecutive_failures = self.health_checks[check_id].consecutive_failures + 1\n",
    "            \n",
    "            self.health_checks[check_id] = health_check\n",
    "            return health_check\n",
    "            \n",
    "        except Exception as e:\n",
    "            response_time = (time.time() - start_time) * 1000\n",
    "            \n",
    "            health_check = HealthCheck(\n",
    "                check_id=check_id,\n",
    "                name=check_id,\n",
    "                status=HealthStatus.UNHEALTHY,\n",
    "                response_time_ms=response_time,\n",
    "                details={\"error\": str(e)},\n",
    "                last_failure=datetime.now(timezone.utc)\n",
    "            )\n",
    "            \n",
    "            if check_id in self.health_checks:\n",
    "                health_check.consecutive_failures = self.health_checks[check_id].consecutive_failures + 1\n",
    "            \n",
    "            self.health_checks[check_id] = health_check\n",
    "            self.logger.error(f\"Health check {check_id} failed\", error=str(e))\n",
    "            return health_check\n",
    "    \n",
    "    def run_all_checks(self) -> Dict[str, HealthCheck]:\n",
    "        \"\"\"Run all registered health checks.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            future_to_check = {\n",
    "                executor.submit(self.run_check, check_id): check_id\n",
    "                for check_id in self.check_functions.keys()\n",
    "            }\n",
    "            \n",
    "            for future in future_to_check:\n",
    "                check_id = future_to_check[future]\n",
    "                try:\n",
    "                    results[check_id] = future.result(timeout=30)\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Health check {check_id} execution failed\", error=str(e))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_system_health(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get overall system health status.\"\"\"\n",
    "        if not self.health_checks:\n",
    "            return {\n",
    "                \"status\": HealthStatus.UNKNOWN,\n",
    "                \"checks\": {},\n",
    "                \"summary\": \"No health checks registered\"\n",
    "            }\n",
    "        \n",
    "        healthy_checks = sum(1 for check in self.health_checks.values() if check.is_healthy())\n",
    "        total_checks = len(self.health_checks)\n",
    "        \n",
    "        # Determine overall status\n",
    "        if healthy_checks == total_checks:\n",
    "            overall_status = HealthStatus.HEALTHY\n",
    "        elif healthy_checks > total_checks * 0.5:\n",
    "            overall_status = HealthStatus.DEGRADED\n",
    "        else:\n",
    "            overall_status = HealthStatus.UNHEALTHY\n",
    "        \n",
    "        return {\n",
    "            \"status\": overall_status,\n",
    "            \"checks\": {check_id: check.dict() for check_id, check in self.health_checks.items()},\n",
    "            \"summary\": {\n",
    "                \"total_checks\": total_checks,\n",
    "                \"healthy_checks\": healthy_checks,\n",
    "                \"health_percentage\": (healthy_checks / total_checks) * 100 if total_checks > 0 else 0\n",
    "            },\n",
    "            \"last_check\": max(\n",
    "                (check.checked_at for check in self.health_checks.values()),\n",
    "                default=datetime.now(timezone.utc)\n",
    "            ).isoformat()\n",
    "        }\n",
    "    \n",
    "    def _register_default_checks(self) -> None:\n",
    "        \"\"\"Register default health checks.\"\"\"\n",
    "        \n",
    "        def check_customer_io_api():\n",
    "            \"\"\"Check Customer.IO API connectivity.\"\"\"\n",
    "            try:\n",
    "                # Simple API health check (would be implemented based on actual API)\n",
    "                # For now, simulate a check\n",
    "                response_time = 0.05  # Simulated response time\n",
    "                return {\n",
    "                    \"name\": \"Customer.IO API\",\n",
    "                    \"status\": HealthStatus.HEALTHY,\n",
    "                    \"details\": {\n",
    "                        \"response_time_ms\": response_time * 1000,\n",
    "                        \"endpoint\": \"api.customer.io\"\n",
    "                    }\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"name\": \"Customer.IO API\",\n",
    "                    \"status\": HealthStatus.UNHEALTHY,\n",
    "                    \"details\": {\"error\": str(e)}\n",
    "                }\n",
    "        \n",
    "        def check_system_resources():\n",
    "            \"\"\"Check system resource utilization.\"\"\"\n",
    "            try:\n",
    "                cpu_percent = psutil.cpu_percent(interval=1)\n",
    "                memory = psutil.virtual_memory()\n",
    "                disk = psutil.disk_usage('/')\n",
    "                \n",
    "                # Determine status based on resource usage\n",
    "                if cpu_percent > 90 or memory.percent > 90 or disk.percent > 90:\n",
    "                    status = HealthStatus.UNHEALTHY\n",
    "                elif cpu_percent > 70 or memory.percent > 70 or disk.percent > 80:\n",
    "                    status = HealthStatus.DEGRADED\n",
    "                else:\n",
    "                    status = HealthStatus.HEALTHY\n",
    "                \n",
    "                return {\n",
    "                    \"name\": \"System Resources\",\n",
    "                    \"status\": status,\n",
    "                    \"details\": {\n",
    "                        \"cpu_percent\": cpu_percent,\n",
    "                        \"memory_percent\": memory.percent,\n",
    "                        \"disk_percent\": disk.percent,\n",
    "                        \"memory_available_gb\": memory.available / (1024**3),\n",
    "                        \"disk_free_gb\": disk.free / (1024**3)\n",
    "                    }\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"name\": \"System Resources\",\n",
    "                    \"status\": HealthStatus.UNHEALTHY,\n",
    "                    \"details\": {\"error\": str(e)}\n",
    "                }\n",
    "        \n",
    "        def check_thread_pool():\n",
    "            \"\"\"Check thread pool health.\"\"\"\n",
    "            try:\n",
    "                # Simple thread pool check\n",
    "                active_threads = threading.active_count()\n",
    "                \n",
    "                if active_threads > 100:\n",
    "                    status = HealthStatus.DEGRADED\n",
    "                else:\n",
    "                    status = HealthStatus.HEALTHY\n",
    "                \n",
    "                return {\n",
    "                    \"name\": \"Thread Pool\",\n",
    "                    \"status\": status,\n",
    "                    \"details\": {\n",
    "                        \"active_threads\": active_threads,\n",
    "                        \"main_thread_alive\": threading.main_thread().is_alive()\n",
    "                    }\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"name\": \"Thread Pool\",\n",
    "                    \"status\": HealthStatus.UNHEALTHY,\n",
    "                    \"details\": {\"error\": str(e)}\n",
    "                }\n",
    "        \n",
    "        # Register the checks\n",
    "        self.register_check(\"customer_io_api\", \"Customer.IO API\", check_customer_io_api)\n",
    "        self.register_check(\"system_resources\", \"System Resources\", check_system_resources)\n",
    "        self.register_check(\"thread_pool\", \"Thread Pool\", check_thread_pool)\n",
    "    \n",
    "    def _start_health_check_thread(self) -> None:\n",
    "        \"\"\"Start background thread for periodic health checking.\"\"\"\n",
    "        def health_check_worker():\n",
    "            while True:\n",
    "                time.sleep(60)  # Check every minute\n",
    "                try:\n",
    "                    self.run_all_checks()\n",
    "                except Exception as e:\n",
    "                    self.logger.error(\"Health check execution failed\", error=str(e))\n",
    "        \n",
    "        thread = threading.Thread(target=health_check_worker, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "print(\"SUCCESS: HealthMonitor class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Tracing System\n",
    "\n",
    "Distributed tracing for complex request flows and performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracingContext:\n",
    "    \"\"\"Thread-local tracing context.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._context = threading.local()\n",
    "    \n",
    "    def set_trace(self, trace_id: str, span_id: str) -> None:\n",
    "        \"\"\"Set current trace context.\"\"\"\n",
    "        self._context.trace_id = trace_id\n",
    "        self._context.span_id = span_id\n",
    "    \n",
    "    def get_trace_id(self) -> Optional[str]:\n",
    "        \"\"\"Get current trace ID.\"\"\"\n",
    "        return getattr(self._context, 'trace_id', None)\n",
    "    \n",
    "    def get_span_id(self) -> Optional[str]:\n",
    "        \"\"\"Get current span ID.\"\"\"\n",
    "        return getattr(self._context, 'span_id', None)\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear trace context.\"\"\"\n",
    "        if hasattr(self._context, 'trace_id'):\n",
    "            delattr(self._context, 'trace_id')\n",
    "        if hasattr(self._context, 'span_id'):\n",
    "            delattr(self._context, 'span_id')\n",
    "\n",
    "class DistributedTracer:\n",
    "    \"\"\"Distributed tracing system for request correlation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spans: Dict[str, List[TraceSpan]] = defaultdict(list)\n",
    "        self.active_spans: Dict[str, TraceSpan] = {}\n",
    "        self.context = TracingContext()\n",
    "        self.logger = structlog.get_logger(\"distributed_tracer\")\n",
    "    \n",
    "    def start_trace(self, operation_name: str, service_name: str = \"default\", tags: Optional[Dict[str, str]] = None) -> TraceSpan:\n",
    "        \"\"\"Start a new trace.\"\"\"\n",
    "        trace_id = str(uuid.uuid4())\n",
    "        span = TraceSpan(\n",
    "            trace_id=trace_id,\n",
    "            operation_name=operation_name,\n",
    "            service_name=service_name,\n",
    "            tags=tags or {}\n",
    "        )\n",
    "        \n",
    "        self.spans[trace_id].append(span)\n",
    "        self.active_spans[span.span_id] = span\n",
    "        self.context.set_trace(trace_id, span.span_id)\n",
    "        \n",
    "        self.logger.info(\n",
    "            \"Trace started\",\n",
    "            trace_id=trace_id,\n",
    "            span_id=span.span_id,\n",
    "            operation=operation_name\n",
    "        )\n",
    "        \n",
    "        return span\n",
    "    \n",
    "    def start_span(self, operation_name: str, service_name: str = \"default\", tags: Optional[Dict[str, str]] = None) -> TraceSpan:\n",
    "        \"\"\"Start a child span.\"\"\"\n",
    "        trace_id = self.context.get_trace_id()\n",
    "        parent_span_id = self.context.get_span_id()\n",
    "        \n",
    "        if not trace_id:\n",
    "            # No active trace, start a new one\n",
    "            return self.start_trace(operation_name, service_name, tags)\n",
    "        \n",
    "        span = TraceSpan(\n",
    "            trace_id=trace_id,\n",
    "            parent_span_id=parent_span_id,\n",
    "            operation_name=operation_name,\n",
    "            service_name=service_name,\n",
    "            tags=tags or {}\n",
    "        )\n",
    "        \n",
    "        self.spans[trace_id].append(span)\n",
    "        self.active_spans[span.span_id] = span\n",
    "        self.context.set_trace(trace_id, span.span_id)\n",
    "        \n",
    "        self.logger.info(\n",
    "            \"Span started\",\n",
    "            trace_id=trace_id,\n",
    "            span_id=span.span_id,\n",
    "            parent_span_id=parent_span_id,\n",
    "            operation=operation_name\n",
    "        )\n",
    "        \n",
    "        return span\n",
    "    \n",
    "    def finish_span(self, span: TraceSpan, status: TraceStatus = TraceStatus.SUCCESS) -> None:\n",
    "        \"\"\"Finish a span.\"\"\"\n",
    "        span.finish(status)\n",
    "        \n",
    "        if span.span_id in self.active_spans:\n",
    "            del self.active_spans[span.span_id]\n",
    "        \n",
    "        # If this was the current span, revert to parent\n",
    "        if self.context.get_span_id() == span.span_id:\n",
    "            if span.parent_span_id:\n",
    "                self.context.set_trace(span.trace_id, span.parent_span_id)\n",
    "            else:\n",
    "                self.context.clear()\n",
    "        \n",
    "        self.logger.info(\n",
    "            \"Span finished\",\n",
    "            trace_id=span.trace_id,\n",
    "            span_id=span.span_id,\n",
    "            duration_ms=span.duration_ms,\n",
    "            status=status\n",
    "        )\n",
    "    \n",
    "    def add_span_log(self, level: str, message: str, **kwargs) -> None:\n",
    "        \"\"\"Add log to current span.\"\"\"\n",
    "        span_id = self.context.get_span_id()\n",
    "        if span_id and span_id in self.active_spans:\n",
    "            self.active_spans[span_id].add_log(level, message, **kwargs)\n",
    "    \n",
    "    def get_trace(self, trace_id: str) -> List[TraceSpan]:\n",
    "        \"\"\"Get all spans for a trace.\"\"\"\n",
    "        return self.spans.get(trace_id, [])\n",
    "    \n",
    "    def get_trace_tree(self, trace_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get trace as hierarchical tree structure.\"\"\"\n",
    "        spans = self.get_trace(trace_id)\n",
    "        if not spans:\n",
    "            return {}\n",
    "        \n",
    "        # Build tree structure\n",
    "        span_map = {span.span_id: span for span in spans}\n",
    "        root_spans = [span for span in spans if span.parent_span_id is None]\n",
    "        \n",
    "        def build_tree(span: TraceSpan) -> Dict[str, Any]:\n",
    "            children = [s for s in spans if s.parent_span_id == span.span_id]\n",
    "            return {\n",
    "                \"span\": span.dict(),\n",
    "                \"children\": [build_tree(child) for child in children]\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"trace_id\": trace_id,\n",
    "            \"total_spans\": len(spans),\n",
    "            \"total_duration_ms\": sum(span.duration_ms or 0 for span in spans),\n",
    "            \"root_spans\": [build_tree(root) for root in root_spans]\n",
    "        }\n",
    "    \n",
    "    def get_tracing_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get tracing system statistics.\"\"\"\n",
    "        total_traces = len(self.spans)\n",
    "        total_spans = sum(len(spans) for spans in self.spans.values())\n",
    "        active_spans_count = len(self.active_spans)\n",
    "        \n",
    "        # Calculate average trace duration\n",
    "        completed_traces = []\n",
    "        for spans in self.spans.values():\n",
    "            if spans and all(span.end_time for span in spans):\n",
    "                trace_duration = sum(span.duration_ms or 0 for span in spans)\n",
    "                completed_traces.append(trace_duration)\n",
    "        \n",
    "        avg_trace_duration = statistics.mean(completed_traces) if completed_traces else 0\n",
    "        \n",
    "        return {\n",
    "            \"total_traces\": total_traces,\n",
    "            \"total_spans\": total_spans,\n",
    "            \"active_spans\": active_spans_count,\n",
    "            \"completed_traces\": len(completed_traces),\n",
    "            \"average_trace_duration_ms\": round(avg_trace_duration, 2),\n",
    "            \"average_spans_per_trace\": round(total_spans / total_traces, 1) if total_traces > 0 else 0\n",
    "        }\n",
    "\n",
    "# Decorator for automatic tracing\n",
    "def trace_function(operation_name: Optional[str] = None, service_name: str = \"default\"):\n",
    "    \"\"\"Decorator for automatic function tracing.\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            tracer = getattr(wrapper, '_tracer', None)\n",
    "            if not tracer:\n",
    "                # Create a default tracer if none exists\n",
    "                tracer = DistributedTracer()\n",
    "                wrapper._tracer = tracer\n",
    "            \n",
    "            op_name = operation_name or f\"{func.__module__}.{func.__name__}\"\n",
    "            span = tracer.start_span(op_name, service_name)\n",
    "            \n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                tracer.finish_span(span, TraceStatus.SUCCESS)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                span.add_log(\"error\", str(e))\n",
    "                tracer.finish_span(span, TraceStatus.ERROR)\n",
    "                raise\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "print(\"SUCCESS: DistributedTracer class and decorator defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main ObservabilityManager Class\n",
    "\n",
    "Comprehensive observability management combining all monitoring components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservabilityManager:\n",
    "    \"\"\"Comprehensive monitoring and observability management.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: CustomerIOClient):\n",
    "        self.client = client\n",
    "        self.logger = structlog.get_logger(\"observability_manager\")\n",
    "        \n",
    "        # Initialize monitoring components\n",
    "        self.metrics_collector = MetricsCollector()\n",
    "        self.alert_manager = AlertManager(self.metrics_collector)\n",
    "        self.health_monitor = HealthMonitor(client)\n",
    "        self.tracer = DistributedTracer()\n",
    "        \n",
    "        # System state tracking\n",
    "        self.start_time = datetime.now(timezone.utc)\n",
    "        self.request_count = 0\n",
    "        self.error_count = 0\n",
    "        \n",
    "        self.logger.info(\"ObservabilityManager initialized\")\n",
    "    \n",
    "    def record_request(self, operation: str, duration_ms: float, success: bool = True, tags: Optional[Dict[str, str]] = None) -> None:\n",
    "        \"\"\"Record a request with comprehensive metrics.\"\"\"\n",
    "        self.request_count += 1\n",
    "        if not success:\n",
    "            self.error_count += 1\n",
    "        \n",
    "        # Record metrics\n",
    "        self.metrics_collector.record_counter(\n",
    "            \"requests_total\",\n",
    "            tags={\"operation\": operation, \"success\": str(success), **(tags or {})}\n",
    "        )\n",
    "        \n",
    "        self.metrics_collector.record_timer(\n",
    "            \"request_duration_ms\",\n",
    "            duration_ms,\n",
    "            tags={\"operation\": operation, **(tags or {})}\n",
    "        )\n",
    "        \n",
    "        if not success:\n",
    "            self.metrics_collector.record_counter(\n",
    "                \"requests_errors_total\",\n",
    "                tags={\"operation\": operation, **(tags or {})}\n",
    "            )\n",
    "    \n",
    "    def record_customer_io_event(self, event_type: str, user_id: str, success: bool = True, response_time_ms: Optional[float] = None) -> None:\n",
    "        \"\"\"Record Customer.IO specific event metrics.\"\"\"\n",
    "        tags = {\n",
    "            \"event_type\": event_type,\n",
    "            \"success\": str(success)\n",
    "        }\n",
    "        \n",
    "        self.metrics_collector.record_counter(\"customerio_events_total\", tags=tags)\n",
    "        \n",
    "        if response_time_ms:\n",
    "            self.metrics_collector.record_timer(\"customerio_response_time_ms\", response_time_ms, tags=tags)\n",
    "        \n",
    "        if not success:\n",
    "            self.metrics_collector.record_counter(\"customerio_events_errors_total\", tags=tags)\n",
    "    \n",
    "    def record_batch_operation(self, batch_size: int, processing_time_ms: float, success_count: int, error_count: int) -> None:\n",
    "        \"\"\"Record batch operation metrics.\"\"\"\n",
    "        self.metrics_collector.record_gauge(\"batch_size\", batch_size)\n",
    "        self.metrics_collector.record_timer(\"batch_processing_time_ms\", processing_time_ms)\n",
    "        self.metrics_collector.record_gauge(\"batch_success_rate\", (success_count / batch_size) * 100 if batch_size > 0 else 0)\n",
    "        \n",
    "        if error_count > 0:\n",
    "            self.metrics_collector.record_counter(\"batch_errors_total\", value=error_count)\n",
    "    \n",
    "    def start_trace(self, operation: str, service: str = \"customer_io\", **tags) -> TraceSpan:\n",
    "        \"\"\"Start distributed trace for operation.\"\"\"\n",
    "        return self.tracer.start_trace(operation, service, tags)\n",
    "    \n",
    "    def start_span(self, operation: str, service: str = \"customer_io\", **tags) -> TraceSpan:\n",
    "        \"\"\"Start span within current trace.\"\"\"\n",
    "        return self.tracer.start_span(operation, service, tags)\n",
    "    \n",
    "    def finish_span(self, span: TraceSpan, success: bool = True) -> None:\n",
    "        \"\"\"Finish span with status.\"\"\"\n",
    "        status = TraceStatus.SUCCESS if success else TraceStatus.ERROR\n",
    "        self.tracer.finish_span(span, status)\n",
    "    \n",
    "    def setup_default_alerts(self) -> None:\n",
    "        \"\"\"Setup default alerting rules.\"\"\"\n",
    "        # High error rate alert\n",
    "        error_rate_rule = AlertRule(\n",
    "            name=\"High Error Rate\",\n",
    "            metric_name=\"error_rate_percent\",\n",
    "            condition=\">\",\n",
    "            threshold=5.0,\n",
    "            severity=AlertSeverity.HIGH,\n",
    "            window_minutes=5,\n",
    "            consecutive_violations=2\n",
    "        )\n",
    "        self.alert_manager.add_rule(error_rate_rule)\n",
    "        \n",
    "        # High response time alert\n",
    "        response_time_rule = AlertRule(\n",
    "            name=\"High Response Time\",\n",
    "            metric_name=\"avg_response_time_ms\",\n",
    "            condition=\">\",\n",
    "            threshold=5000.0,\n",
    "            severity=AlertSeverity.MEDIUM,\n",
    "            window_minutes=10,\n",
    "            consecutive_violations=3\n",
    "        )\n",
    "        self.alert_manager.add_rule(response_time_rule)\n",
    "        \n",
    "        # System resource alerts\n",
    "        cpu_rule = AlertRule(\n",
    "            name=\"High CPU Usage\",\n",
    "            metric_name=\"cpu_percent\",\n",
    "            condition=\">\",\n",
    "            threshold=80.0,\n",
    "            severity=AlertSeverity.MEDIUM,\n",
    "            window_minutes=15\n",
    "        )\n",
    "        self.alert_manager.add_rule(cpu_rule)\n",
    "        \n",
    "        memory_rule = AlertRule(\n",
    "            name=\"High Memory Usage\",\n",
    "            metric_name=\"memory_percent\",\n",
    "            condition=\">\",\n",
    "            threshold=85.0,\n",
    "            severity=AlertSeverity.HIGH,\n",
    "            window_minutes=10\n",
    "        )\n",
    "        self.alert_manager.add_rule(memory_rule)\n",
    "        \n",
    "        self.logger.info(\"Default alert rules configured\")\n",
    "    \n",
    "    def get_dashboard_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive dashboard data.\"\"\"\n",
    "        # Calculate uptime\n",
    "        uptime_seconds = (datetime.now(timezone.utc) - self.start_time).total_seconds()\n",
    "        \n",
    "        # Calculate error rate\n",
    "        error_rate = (self.error_count / self.request_count) * 100 if self.request_count > 0 else 0\n",
    "        \n",
    "        # Update error rate metric for alerting\n",
    "        self.metrics_collector.record_gauge(\"error_rate_percent\", error_rate)\n",
    "        \n",
    "        # Get system health\n",
    "        system_health = self.health_monitor.get_system_health()\n",
    "        \n",
    "        # Get metrics statistics\n",
    "        request_stats = self.metrics_collector.get_metric_statistics(\"request_duration_ms\", MetricType.TIMER)\n",
    "        if request_stats:\n",
    "            self.metrics_collector.record_gauge(\"avg_response_time_ms\", request_stats.get(\"mean\", 0))\n",
    "        \n",
    "        return {\n",
    "            \"system\": {\n",
    "                \"uptime_seconds\": uptime_seconds,\n",
    "                \"start_time\": self.start_time.isoformat(),\n",
    "                \"health_status\": system_health[\"status\"],\n",
    "                \"health_summary\": system_health[\"summary\"]\n",
    "            },\n",
    "            \"requests\": {\n",
    "                \"total_requests\": self.request_count,\n",
    "                \"total_errors\": self.error_count,\n",
    "                \"error_rate_percent\": round(error_rate, 2),\n",
    "                \"requests_per_minute\": round(self.request_count / (uptime_seconds / 60), 2) if uptime_seconds > 0 else 0\n",
    "            },\n",
    "            \"performance\": request_stats,\n",
    "            \"alerts\": {\n",
    "                \"active_alerts\": len(self.alert_manager.get_active_alerts()),\n",
    "                \"critical_alerts\": len(self.alert_manager.get_active_alerts(AlertSeverity.CRITICAL)),\n",
    "                \"alert_statistics\": self.alert_manager.get_alert_statistics()\n",
    "            },\n",
    "            \"tracing\": self.tracer.get_tracing_statistics(),\n",
    "            \"metrics\": self.metrics_collector.get_buffer_status(),\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "        }\n",
    "    \n",
    "    def generate_health_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive health report.\"\"\"\n",
    "        health_checks = self.health_monitor.run_all_checks()\n",
    "        system_health = self.health_monitor.get_system_health()\n",
    "        active_alerts = self.alert_manager.get_active_alerts()\n",
    "        \n",
    "        # Analyze system trends\n",
    "        dashboard_data = self.get_dashboard_data()\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Generate recommendations based on metrics\n",
    "        if dashboard_data[\"requests\"][\"error_rate_percent\"] > 5:\n",
    "            recommendations.append(\"High error rate detected - investigate recent changes\")\n",
    "        \n",
    "        if len(active_alerts) > 0:\n",
    "            recommendations.append(f\"Active alerts require attention: {len(active_alerts)} alerts\")\n",
    "        \n",
    "        if system_health[\"status\"] != HealthStatus.HEALTHY:\n",
    "            recommendations.append(\"System health degraded - check resource utilization\")\n",
    "        \n",
    "        return {\n",
    "            \"report_generated_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"overall_health\": system_health[\"status\"],\n",
    "            \"health_checks\": health_checks,\n",
    "            \"active_alerts\": [alert.dict() for alert in active_alerts],\n",
    "            \"system_metrics\": dashboard_data,\n",
    "            \"recommendations\": recommendations,\n",
    "            \"summary\": {\n",
    "                \"total_health_checks\": len(health_checks),\n",
    "                \"passing_health_checks\": len([check for check in health_checks.values() if check.is_healthy()]),\n",
    "                \"active_alert_count\": len(active_alerts),\n",
    "                \"critical_alert_count\": len([alert for alert in active_alerts if alert.severity == AlertSeverity.CRITICAL])\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get ObservabilityManager metrics and status.\"\"\"\n",
    "        return {\n",
    "            \"manager\": {\n",
    "                \"start_time\": self.start_time.isoformat(),\n",
    "                \"uptime_seconds\": (datetime.now(timezone.utc) - self.start_time).total_seconds(),\n",
    "                \"total_requests\": self.request_count,\n",
    "                \"total_errors\": self.error_count\n",
    "            },\n",
    "            \"components\": {\n",
    "                \"metrics_collector\": self.metrics_collector.get_buffer_status(),\n",
    "                \"alert_manager\": self.alert_manager.get_alert_statistics(),\n",
    "                \"health_monitor\": {\n",
    "                    \"registered_checks\": len(self.health_monitor.check_functions),\n",
    "                    \"last_check_results\": len(self.health_monitor.health_checks)\n",
    "                },\n",
    "                \"tracer\": self.tracer.get_tracing_statistics()\n",
    "            },\n",
    "            \"features\": {\n",
    "                \"metrics_collection\": True,\n",
    "                \"alerting\": True,\n",
    "                \"health_monitoring\": True,\n",
    "                \"distributed_tracing\": True,\n",
    "                \"dashboard_data\": True,\n",
    "                \"health_reporting\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"SUCCESS: ObservabilityManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage and Testing\n",
    "\n",
    "Comprehensive examples demonstrating observability features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize observability manager\n",
    "try:\n",
    "    client = CustomerIOClient(\n",
    "        site_id=\"test_site_123\",\n",
    "        api_key=\"test_key_456\",\n",
    "        region=\"us\"\n",
    "    )\n",
    "    \n",
    "    observability = ObservabilityManager(client)\n",
    "    observability.setup_default_alerts()\n",
    "    \n",
    "    print(\"SUCCESS: ObservabilityManager initialized with default configuration\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to initialize ObservabilityManager: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Record various metrics\n",
    "try:\n",
    "    # Simulate some operations\n",
    "    import random\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Simulate API requests with varying response times\n",
    "        response_time = random.uniform(50, 2000)  # 50ms to 2s\n",
    "        success = random.random() > 0.1  # 90% success rate\n",
    "        \n",
    "        observability.record_request(\n",
    "            operation=\"api_call\",\n",
    "            duration_ms=response_time,\n",
    "            success=success,\n",
    "            tags={\"endpoint\": \"/api/track\"}\n",
    "        )\n",
    "        \n",
    "        # Simulate Customer.IO events\n",
    "        observability.record_customer_io_event(\n",
    "            event_type=\"track\",\n",
    "            user_id=f\"user_{i}\",\n",
    "            success=success,\n",
    "            response_time_ms=response_time\n",
    "        )\n",
    "    \n",
    "    # Simulate batch operations\n",
    "    observability.record_batch_operation(\n",
    "        batch_size=100,\n",
    "        processing_time_ms=1500,\n",
    "        success_count=95,\n",
    "        error_count=5\n",
    "    )\n",
    "    \n",
    "    print(\"SUCCESS: Sample metrics recorded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to record metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Distributed tracing\n",
    "try:\n",
    "    # Start a trace for a complex operation\n",
    "    trace = observability.start_trace(\n",
    "        \"user_registration_flow\",\n",
    "        service=\"user_service\",\n",
    "        user_id=\"user_12345\",\n",
    "        flow_type=\"registration\"\n",
    "    )\n",
    "    \n",
    "    # Simulate sub-operations\n",
    "    validation_span = observability.start_span(\n",
    "        \"validate_user_data\",\n",
    "        service=\"validation_service\"\n",
    "    )\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    observability.tracer.add_span_log(\"info\", \"User data validated successfully\")\n",
    "    observability.finish_span(validation_span, success=True)\n",
    "    \n",
    "    db_span = observability.start_span(\n",
    "        \"create_user_record\",\n",
    "        service=\"database_service\"\n",
    "    )\n",
    "    time.sleep(0.05)  # Simulate work\n",
    "    observability.tracer.add_span_log(\"info\", \"User record created\", user_id=\"user_12345\")\n",
    "    observability.finish_span(db_span, success=True)\n",
    "    \n",
    "    cio_span = observability.start_span(\n",
    "        \"send_welcome_event\",\n",
    "        service=\"customer_io\"\n",
    "    )\n",
    "    time.sleep(0.2)  # Simulate API call\n",
    "    observability.tracer.add_span_log(\"info\", \"Welcome event sent to Customer.IO\")\n",
    "    observability.finish_span(cio_span, success=True)\n",
    "    \n",
    "    # Finish the main trace\n",
    "    observability.finish_span(trace, success=True)\n",
    "    \n",
    "    # Get trace tree\n",
    "    trace_tree = observability.tracer.get_trace_tree(trace.trace_id)\n",
    "    print(f\"SUCCESS: Trace completed with {trace_tree['total_spans']} spans\")\n",
    "    print(f\"Total trace duration: {trace_tree['total_duration_ms']:.2f}ms\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Tracing failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Health monitoring\n",
    "try:\n",
    "    # Run health checks\n",
    "    health_results = observability.health_monitor.run_all_checks()\n",
    "    \n",
    "    print(\"Health Check Results:\")\n",
    "    for check_id, check in health_results.items():\n",
    "        status_icon = \"\" if check.is_healthy() else \"\"\n",
    "        print(f\"  {status_icon} {check.name}: {check.status} ({check.response_time_ms:.1f}ms)\")\n",
    "    \n",
    "    # Get overall system health\n",
    "    system_health = observability.health_monitor.get_system_health()\n",
    "    print(f\"\\nOverall System Health: {system_health['status']}\")\n",
    "    print(f\"Health Percentage: {system_health['summary']['health_percentage']:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Health monitoring failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Dashboard data and alerting\n",
    "try:\n",
    "    # Get dashboard data\n",
    "    dashboard = observability.get_dashboard_data()\n",
    "    \n",
    "    print(\"Dashboard Summary:\")\n",
    "    print(f\"  System Uptime: {dashboard['system']['uptime_seconds']:.1f} seconds\")\n",
    "    print(f\"  Total Requests: {dashboard['requests']['total_requests']}\")\n",
    "    print(f\"  Error Rate: {dashboard['requests']['error_rate_percent']}%\")\n",
    "    print(f\"  Requests/Minute: {dashboard['requests']['requests_per_minute']:.1f}\")\n",
    "    print(f\"  Active Alerts: {dashboard['alerts']['active_alerts']}\")\n",
    "    print(f\"  Health Status: {dashboard['system']['health_status']}\")\n",
    "    \n",
    "    # Check for active alerts\n",
    "    active_alerts = observability.alert_manager.get_active_alerts()\n",
    "    if active_alerts:\n",
    "        print(\"\\nActive Alerts:\")\n",
    "        for alert in active_alerts:\n",
    "            print(f\"  - {alert.name} ({alert.severity}): {alert.message}\")\n",
    "    else:\n",
    "        print(\"\\nNo active alerts\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Dashboard data retrieval failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate comprehensive health report\n",
    "try:\n",
    "    # Allow some time for metrics to accumulate\n",
    "    time.sleep(1)\n",
    "    \n",
    "    health_report = observability.generate_health_report()\n",
    "    \n",
    "    print(\"Health Report Summary:\")\n",
    "    print(f\"  Report Generated: {health_report['report_generated_at']}\")\n",
    "    print(f\"  Overall Health: {health_report['overall_health']}\")\n",
    "    print(f\"  Health Checks: {health_report['summary']['passing_health_checks']}/{health_report['summary']['total_health_checks']} passing\")\n",
    "    print(f\"  Active Alerts: {health_report['summary']['active_alert_count']}\")\n",
    "    print(f\"  Critical Alerts: {health_report['summary']['critical_alert_count']}\")\n",
    "    \n",
    "    if health_report['recommendations']:\n",
    "        print(\"\\nRecommendations:\")\n",
    "        for rec in health_report['recommendations']:\n",
    "            print(f\"  - {rec}\")\n",
    "    else:\n",
    "        print(\"\\nNo recommendations at this time\")\n",
    "    \n",
    "    # Show metrics summary\n",
    "    metrics = observability.get_metrics()\n",
    "    print(f\"\\nObservability Manager Status:\")\n",
    "    print(f\"  Uptime: {metrics['manager']['uptime_seconds']:.1f} seconds\")\n",
    "    print(f\"  Total Requests Processed: {metrics['manager']['total_requests']}\")\n",
    "    print(f\"  Buffer Utilization: {metrics['components']['metrics_collector']['buffer_utilization']:.1f}%\")\n",
    "    print(f\"  Tracing Statistics: {metrics['components']['tracer']['total_traces']} traces, {metrics['components']['tracer']['total_spans']} spans\")\n",
    "    \n",
    "    print(\"\\nSUCCESS: Comprehensive monitoring and observability system operational\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Health report generation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates a comprehensive monitoring and observability solution for Customer.IO data pipelines including:\n",
    "\n",
    "**Core Features:**\n",
    "- **MetricsCollector**: High-performance metrics collection with buffering and aggregation\n",
    "- **AlertManager**: Intelligent alerting system with threshold management and notification routing\n",
    "- **HealthMonitor**: Comprehensive health checks for services and dependencies\n",
    "- **DistributedTracer**: Distributed tracing for complex request flows and performance analysis\n",
    "- **ObservabilityManager**: Unified management of all monitoring components\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Real-time metrics collection (counters, gauges, timers, histograms)\n",
    "- Configurable alerting rules with multiple severity levels\n",
    "- System resource monitoring and health checks\n",
    "- Request correlation through distributed tracing\n",
    "- Performance analytics and SLA monitoring\n",
    "- Comprehensive dashboard data generation\n",
    "- Automated health reporting with recommendations\n",
    "\n",
    "**Integration Points:**\n",
    "- Customer.IO API monitoring and performance tracking\n",
    "- Batch operation monitoring and optimization\n",
    "- Error tracking and alerting\n",
    "- System resource utilization monitoring\n",
    "- Custom health check registration\n",
    "\n",
    "The system is designed for production use with thread-safe operations, background processing, and comprehensive error handling. Ready for integration with external monitoring systems and dashboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}