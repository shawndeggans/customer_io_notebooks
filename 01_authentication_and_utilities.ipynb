{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer.IO Data Pipelines API - Authentication and Utilities\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates how to authenticate with Customer.IO's Data Pipelines API and use the utility modules we've created.\n",
    "It covers API client initialization, testing connections, and demonstrates core functionality with real examples.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Complete setup from `00_setup_and_configuration.ipynb`\n",
    "- Customer.IO API key configured in Databricks secrets\n",
    "- Utility modules (`utils/`) available in the Python path\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **API Authentication**: Using API keys with Basic Auth\n",
    "- **Rate Limiting**: Handling 3000 requests per 3 seconds limit\n",
    "- **Error Handling**: Retry logic and graceful degradation\n",
    "- **Request Validation**: Using Pydantic models for data validation\n",
    "- **Data Transformation**: Converting between formats for API consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import standard libraries\nimport sys\nimport os\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Optional, Any\nimport json\nimport time\n\n# Add utils directory to Python path\nsys.path.append('/Workspace/Repos/customer_io_notebooks/utils')\n\n# Import Customer.IO utilities\nfrom utils.api_client import CustomerIOClient\nfrom utils.validators import (\n    IdentifyRequest, \n    TrackRequest, \n    GroupRequest,\n    validate_request_size,\n    create_context\n)\nfrom utils.transformers import (\n    CustomerTransformer,\n    EventTransformer,\n    BatchTransformer,\n    ContextTransformer\n)\nfrom utils.error_handlers import (\n    CustomerIOError,\n    RateLimitError,\n    ValidationError,\n    NetworkError,\n    retry_on_error,\n    ErrorContext\n)\n\n# Databricks and Spark imports\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom delta.tables import DeltaTable\n\n# Validation and logging\nimport structlog\nfrom pydantic import ValidationError as PydanticValidationError\n\n# Initialize logger\nlogger = structlog.get_logger(\"customerio_demo\")\n\nprint(\"SUCCESS: All imports successful\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration from widgets (set in previous notebook)\n",
    "CUSTOMERIO_API_KEY = dbutils.widgets.get(\"customerio_api_key\") or \"test_key_demo_12345\"\n",
    "CUSTOMERIO_REGION = dbutils.widgets.get(\"customerio_region\") or \"us\"\n",
    "DATABASE_NAME = dbutils.widgets.get(\"database_name\") or \"customerio_demo\"\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\") or \"main\"\n",
    "ENVIRONMENT = dbutils.widgets.get(\"environment\") or \"test\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Region: {CUSTOMERIO_REGION}\")\n",
    "print(f\"  Database: {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "print(f\"  Environment: {ENVIRONMENT}\")\n",
    "print(f\"  API Key: {'*' * (len(CUSTOMERIO_API_KEY) - 4) + CUSTOMERIO_API_KEY[-4:]}\")\n",
    "\n",
    "# Use current database\n",
    "spark.sql(f\"USE {CATALOG_NAME}.{DATABASE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Customer.IO API Client"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the Customer.IO client with proper configuration\ntry:\n    client = CustomerIOClient(\n        api_key=CUSTOMERIO_API_KEY,\n        region=CUSTOMERIO_REGION,\n        timeout=30,\n        max_retries=3,\n        retry_backoff_factor=2.0,\n        enable_logging=True,\n        spark_session=spark\n    )\n    \n    print(\"SUCCESS: Customer.IO client initialized successfully\")\n    print(f\"   Base URL: {client.base_url}\")\n    print(f\"   Rate Limit: {client.rate_limit.max_requests} requests per {client.rate_limit.window_seconds} seconds\")\n    print(f\"   Max Retries: {client.max_retries}\")\n    print(f\"   Logging Enabled: {client.enable_logging}\")\n    \nexcept Exception as e:\n    print(f\"ERROR: Failed to initialize Customer.IO client: {str(e)}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test API Connection and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test API connection with health check\nprint(\"Testing API connection...\")\n\ntry:\n    # Test with region endpoint (safest test call)\n    if ENVIRONMENT != \"test\":  # Only make real API calls in non-test environments\n        region_info = client.get_region()\n        print(f\"SUCCESS: API connection successful\")\n        print(f\"   Region response: {region_info}\")\n        \n        # Test health check method\n        is_healthy = client.health_check()\n        print(f\"   Health check: {'SUCCESS: Healthy' if is_healthy else 'ERROR: Unhealthy'}\")\n    else:\n        print(\"WARNING: Running in test mode - skipping actual API calls\")\n        print(\"   Client configured correctly for when real API key is available\")\n        \nexcept CustomerIOError as e:\n    print(f\"ERROR: Customer.IO API Error: {str(e)}\")\n    if hasattr(e, 'status_code'):\n        print(f\"   Status Code: {e.status_code}\")\nexcept NetworkError as e:\n    print(f\"ERROR: Network Error: {str(e)}\")\nexcept Exception as e:\n    print(f\"ERROR: Unexpected Error: {str(e)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Request Validation with Pydantic Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Example 1: Valid identify request\nprint(\"=== Testing Request Validation ===\")\nprint(\"\\n1. Valid Identify Request:\")\n\ntry:\n    valid_identify = IdentifyRequest(\n        userId=\"user_12345\",\n        traits={\n            \"email\": \"user@example.com\",\n            \"first_name\": \"John\",\n            \"last_name\": \"Doe\",\n            \"plan\": \"premium\",\n            \"signup_date\": \"2024-01-15\"\n        },\n        timestamp=datetime.now(timezone.utc)\n    )\n    print(f\"SUCCESS: Valid request created: {valid_identify.dict()}\")\nexcept PydanticValidationError as e:\n    print(f\"ERROR: Validation error: {e}\")\n\n# Example 2: Invalid identify request (missing user identification)\nprint(\"\\n2. Invalid Identify Request (missing user ID):\")\n\ntry:\n    invalid_identify = IdentifyRequest(\n        traits={\"email\": \"user@example.com\"}\n    )\n    print(f\"SUCCESS: Request created: {invalid_identify.dict()}\")\nexcept PydanticValidationError as e:\n    print(f\"ERROR: Expected validation error: {e}\")\n\n# Example 3: Valid track request\nprint(\"\\n3. Valid Track Request:\")\n\ntry:\n    valid_track = TrackRequest(\n        userId=\"user_12345\",\n        event=\"Product Viewed\",\n        properties={\n            \"product_id\": \"prod_abc123\",\n            \"product_name\": \"Awesome Widget\",\n            \"category\": \"electronics\",\n            \"price\": 29.99,\n            \"currency\": \"USD\"\n        },\n        timestamp=datetime.now(timezone.utc)\n    )\n    print(f\"SUCCESS: Valid track request: {valid_track.dict()}\")\nexcept PydanticValidationError as e:\n    print(f\"ERROR: Validation error: {e}\")\n\n# Example 4: Invalid track request (empty event name)\nprint(\"\\n4. Invalid Track Request (empty event name):\")\n\ntry:\n    invalid_track = TrackRequest(\n        userId=\"user_12345\",\n        event=\"\",  # Empty event name\n        properties={\"test\": \"value\"}\n    )\n    print(f\"SUCCESS: Request created: {invalid_track.dict()}\")\nexcept PydanticValidationError as e:\n    print(f\"ERROR: Expected validation error: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample customer data from Delta table\n",
    "print(\"=== Data Transformation Examples ===\")\n",
    "print(\"\\n1. Loading sample customer data:\")\n",
    "\n",
    "customers_df = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.customers\").limit(5)\n",
    "customers_df.show(5, truncate=False)\n",
    "\n",
    "print(f\"Total customers in table: {spark.table(f'{CATALOG_NAME}.{DATABASE_NAME}.customers').count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Spark DataFrame to identify requests\n",
    "print(\"\\n2. Transform to Customer.IO identify requests:\")\n",
    "\n",
    "# Get a small sample for demonstration\n",
    "sample_customers = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.customers\").limit(3)\n",
    "\n",
    "# Transform to identify requests\n",
    "identify_requests = CustomerTransformer.spark_to_identify_requests(\n",
    "    df=sample_customers,\n",
    "    user_id_col=\"user_id\",\n",
    "    email_col=\"email\",\n",
    "    traits_cols=[\"custom_attributes\"],  # Use the map column as traits\n",
    "    timestamp_col=\"created_at\"\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(identify_requests)} identify requests:\")\n",
    "for i, request in enumerate(identify_requests[:2]):  # Show first 2\n",
    "    print(f\"  Request {i+1}: {json.dumps(request, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform event data to track requests\n",
    "print(\"\\n3. Transform events to track requests:\")\n",
    "\n",
    "# Get sample event data\n",
    "sample_events = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.events\").limit(3)\n",
    "sample_events.show(3, truncate=False)\n",
    "\n",
    "# Transform to track requests\n",
    "track_requests = EventTransformer.spark_to_track_requests(\n",
    "    df=sample_events,\n",
    "    user_id_col=\"user_id\",\n",
    "    event_name_col=\"event_name\",\n",
    "    properties_cols=[\"properties\"],  # Use the map column as properties\n",
    "    timestamp_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(track_requests)} track requests:\")\n",
    "for i, request in enumerate(track_requests[:2]):  # Show first 2\n",
    "    print(f\"  Request {i+1}: {json.dumps(request, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Specialized Event Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ecommerce events using transformers\n",
    "print(\"=== Creating Specialized Events ===\")\n",
    "print(\"\\n1. Ecommerce Events:\")\n",
    "\n",
    "# Product viewed event\n",
    "product_viewed = EventTransformer.create_ecommerce_event(\n",
    "    event_name=\"Product Viewed\",\n",
    "    user_id=\"user_demo_001\",\n",
    "    product_id=\"prod_widget_123\",\n",
    "    price=29.99,\n",
    "    quantity=1,\n",
    "    currency=\"USD\",\n",
    "    # Additional properties\n",
    "    product_name=\"Amazing Widget\",\n",
    "    category=\"electronics\",\n",
    "    brand=\"WidgetCorp\",\n",
    "    sku=\"WDG-123-RED\"\n",
    ")\n",
    "\n",
    "print(\"Product Viewed Event:\")\n",
    "print(json.dumps(product_viewed, indent=2))\n",
    "\n",
    "# Order completed event\n",
    "order_completed = EventTransformer.create_ecommerce_event(\n",
    "    event_name=\"Order Completed\",\n",
    "    user_id=\"user_demo_001\",\n",
    "    order_id=\"order_789\",\n",
    "    price=89.97,  # Total order value\n",
    "    currency=\"USD\",\n",
    "    # Additional properties\n",
    "    products=[\n",
    "        {\"product_id\": \"prod_widget_123\", \"quantity\": 3, \"price\": 29.99}\n",
    "    ],\n",
    "    payment_method=\"credit_card\",\n",
    "    shipping_method=\"standard\"\n",
    ")\n",
    "\n",
    "print(\"\\nOrder Completed Event:\")\n",
    "print(json.dumps(order_completed, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mobile app events\n",
    "print(\"\\n2. Mobile App Events:\")\n",
    "\n",
    "# Application opened event\n",
    "app_opened = EventTransformer.create_mobile_app_event(\n",
    "    event_name=\"Application Opened\",\n",
    "    user_id=\"user_mobile_001\",\n",
    "    app_version=\"2.1.0\",\n",
    "    os_version=\"iOS 17.2\",\n",
    "    device_model=\"iPhone 15 Pro\",\n",
    "    # Additional properties\n",
    "    session_id=\"session_abc123\",\n",
    "    from_push_notification=False,\n",
    "    app_build=\"2100\"\n",
    ")\n",
    "\n",
    "print(\"Application Opened Event:\")\n",
    "print(json.dumps(app_opened, indent=2))\n",
    "\n",
    "# Screen viewed event\n",
    "screen_viewed = EventTransformer.create_mobile_app_event(\n",
    "    event_name=\"Screen Viewed\",\n",
    "    user_id=\"user_mobile_001\",\n",
    "    app_version=\"2.1.0\",\n",
    "    # Additional properties\n",
    "    screen_name=\"Product Details\",\n",
    "    screen_category=\"ecommerce\",\n",
    "    product_id=\"prod_widget_123\"\n",
    ")\n",
    "\n",
    "print(\"\\nScreen Viewed Event:\")\n",
    "print(json.dumps(screen_viewed, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Creation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create context objects for different platforms\n",
    "print(\"=== Context Creation Examples ===\")\n",
    "print(\"\\n1. Web Context:\")\n",
    "\n",
    "web_context = ContextTransformer.create_web_context(\n",
    "    ip=\"192.168.1.100\",\n",
    "    user_agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\",\n",
    "    url=\"https://example.com/products/widget-123\",\n",
    "    referrer=\"https://google.com/search\",\n",
    "    locale=\"en-US\",\n",
    "    timezone=\"America/New_York\"\n",
    ")\n",
    "\n",
    "print(json.dumps(web_context, indent=2))\n",
    "\n",
    "print(\"\\n2. Mobile Context:\")\n",
    "\n",
    "mobile_context = ContextTransformer.create_mobile_context(\n",
    "    app_name=\"CustomerIO Demo App\",\n",
    "    app_version=\"2.1.0\",\n",
    "    os_name=\"iOS\",\n",
    "    os_version=\"17.2\",\n",
    "    device_model=\"iPhone 15 Pro\",\n",
    "    device_id=\"device_12345\",\n",
    "    locale=\"en-US\",\n",
    "    timezone=\"America/Los_Angeles\"\n",
    ")\n",
    "\n",
    "print(json.dumps(mobile_context, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Operations and Size Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch requests and optimize sizes\n",
    "print(\"=== Batch Operations ===\")\n",
    "print(\"\\n1. Creating batch requests:\")\n",
    "\n",
    "# Create multiple requests\n",
    "sample_identify = [\n",
    "    {\n",
    "        \"userId\": f\"user_batch_{i}\",\n",
    "        \"traits\": {\n",
    "            \"email\": f\"user{i}@example.com\",\n",
    "            \"plan\": \"premium\" if i % 2 == 0 else \"basic\",\n",
    "            \"signup_date\": \"2024-01-15\"\n",
    "        }\n",
    "    }\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "sample_track = [\n",
    "    {\n",
    "        \"userId\": f\"user_batch_{i}\",\n",
    "        \"event\": \"Page Viewed\",\n",
    "        \"properties\": {\n",
    "            \"page_name\": \"Home\",\n",
    "            \"url\": f\"https://example.com/page-{i}\"\n",
    "        }\n",
    "    }\n",
    "    for i in range(3)\n",
    "]\n",
    "\n",
    "# Create batch request\n",
    "batch_requests = BatchTransformer.create_batch_request(\n",
    "    identify_requests=sample_identify,\n",
    "    track_requests=sample_track,\n",
    "    max_batch_size=10\n",
    ")\n",
    "\n",
    "print(f\"Created {len(batch_requests)} batch(es)\")\n",
    "for i, batch in enumerate(batch_requests):\n",
    "    batch_size = BatchTransformer.estimate_batch_size(batch[\"batch\"])\n",
    "    print(f\"  Batch {i+1}: {len(batch['batch'])} requests, ~{batch_size} bytes\")\n",
    "\n",
    "# Show first batch structure\n",
    "if batch_requests:\n",
    "    print(f\"\\nFirst batch preview (first 2 requests):\")\n",
    "    preview_batch = {\"batch\": batch_requests[0][\"batch\"][:2]}\n",
    "    print(json.dumps(preview_batch, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate batch size optimization\n",
    "print(\"\\n2. Batch size optimization:\")\n",
    "\n",
    "# Create requests with varying sizes\n",
    "large_requests = []\n",
    "for i in range(20):\n",
    "    # Create request with large properties to test size limits\n",
    "    large_request = {\n",
    "        \"userId\": f\"user_large_{i}\",\n",
    "        \"event\": \"Data Import\",\n",
    "        \"properties\": {\n",
    "            \"large_data\": \"x\" * 1000,  # 1KB of data per request\n",
    "            \"import_id\": f\"import_{i}\",\n",
    "            \"batch_number\": i // 5\n",
    "        }\n",
    "    }\n",
    "    large_requests.append(large_request)\n",
    "\n",
    "# Optimize batch sizes to stay within limits\n",
    "optimized_batches = BatchTransformer.optimize_batch_sizes(\n",
    "    requests=large_requests,\n",
    "    max_size_bytes=10 * 1024  # 10KB limit for demo (normally 500KB)\n",
    ")\n",
    "\n",
    "print(f\"Optimized into {len(optimized_batches)} batches:\")\n",
    "for i, batch in enumerate(optimized_batches):\n",
    "    batch_size = BatchTransformer.estimate_batch_size(batch)\n",
    "    print(f\"  Optimized Batch {i+1}: {len(batch)} requests, {batch_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate error handling patterns\n",
    "print(\"=== Error Handling Demonstrations ===\")\n",
    "print(\"\\n1. Error Context Manager:\")\n",
    "\n",
    "# Example of graceful error handling\n",
    "with ErrorContext(\n",
    "    operation_name=\"demo_api_call\",\n",
    "    logger=logger,\n",
    "    raise_on_error=False,\n",
    "    default_return={\"status\": \"failed\", \"message\": \"Operation failed gracefully\"}\n",
    ") as error_ctx:\n",
    "    # Simulate an operation that might fail\n",
    "    if ENVIRONMENT == \"test\":\n",
    "        # Simulate a controlled error for demonstration\n",
    "        raise CustomerIOError(\"Simulated API error for demonstration\")\n",
    "    else:\n",
    "        print(\"Real API call would happen here\")\n",
    "\n",
    "# Check if error occurred and get default result\n",
    "if error_ctx.error:\n",
    "    result = error_ctx.get_result()\n",
    "    print(f\"Error handled gracefully: {result}\")\n",
    "else:\n",
    "    print(\"Operation completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate retry decorator\nprint(\"\\n2. Retry Decorator Example:\")\n\n@retry_on_error(max_retries=2, backoff_factor=1.5)\ndef demo_api_call_with_retry(should_fail: bool = False):\n    \"\"\"Demo function that can be configured to fail for testing.\"\"\"\n    print(f\"  Attempting API call (fail={should_fail})...\")\n    \n    if should_fail:\n        # Simulate different types of failures\n        import random\n        error_type = random.choice([\"network\", \"server\", \"rate_limit\"])\n        \n        if error_type == \"network\":\n            raise NetworkError(\"Simulated network error\")\n        elif error_type == \"server\":\n            raise CustomerIOError(\"Simulated server error\", status_code=500)\n        else:\n            raise RateLimitError(\"Simulated rate limit error\", retry_after=1)\n    \n    return {\"status\": \"success\", \"message\": \"API call completed\"}\n\n# Test successful call\ntry:\n    result = demo_api_call_with_retry(should_fail=False)\n    print(f\"SUCCESS: Success: {result}\")\nexcept Exception as e:\n    print(f\"ERROR: Failed: {str(e)}\")\n\n# Test failing call (will retry)\ntry:\n    result = demo_api_call_with_retry(should_fail=True)\n    print(f\"SUCCESS: Success after retries: {result}\")\nexcept Exception as e:\n    print(f\"ERROR: Failed after retries: {str(e)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limiting Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate rate limiting behavior\nprint(\"=== Rate Limiting Demonstration ===\")\n\n# Check current rate limit status\nprint(f\"Rate limit configuration:\")\nprint(f\"  Max requests: {client.rate_limit.max_requests}\")\nprint(f\"  Window: {client.rate_limit.window_seconds} seconds\")\nprint(f\"  Current requests: {client.rate_limit.current_requests}\")\nprint(f\"  Window start: {client.rate_limit.window_start}\")\n\n# Simulate rate limit checking\nprint(f\"\\nRate limit status:\")\nprint(f\"  Can make request: {client.rate_limit.can_make_request()}\")\nprint(f\"  Time until reset: {client.rate_limit.time_until_reset():.2f} seconds\")\n\n# Simulate some requests to show rate limiting in action\nprint(f\"\\nSimulating request tracking:\")\nfor i in range(5):\n    if client.rate_limit.can_make_request():\n        client.rate_limit.record_request()\n        print(f\"  Request {i+1}: SUCCESS: Allowed (total: {client.rate_limit.current_requests})\")\n    else:\n        print(f\"  Request {i+1}: ERROR: Rate limited\")\n        break"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Size Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate request size validation\n",
    "print(\"=== Request Size Validation ===\")\n",
    "\n",
    "# Test normal-sized request\n",
    "normal_request = {\n",
    "    \"userId\": \"user_123\",\n",
    "    \"event\": \"Page Viewed\",\n",
    "    \"properties\": {\n",
    "        \"page_name\": \"Home\",\n",
    "        \"url\": \"https://example.com\"\n",
    "    }\n",
    "}\n",
    "\n",
    "is_valid_size = validate_request_size(normal_request)\n",
    "print(f\"Normal request size valid: {is_valid_size}\")\n",
    "print(f\"  Request size: ~{len(json.dumps(normal_request).encode())} bytes\")\n",
    "\n",
    "# Test oversized request\n",
    "oversized_request = {\n",
    "    \"userId\": \"user_123\",\n",
    "    \"event\": \"Large Data Import\",\n",
    "    \"properties\": {\n",
    "        \"large_payload\": \"x\" * (33 * 1024),  # 33KB - exceeds 32KB limit\n",
    "        \"import_id\": \"large_import_001\"\n",
    "    }\n",
    "}\n",
    "\n",
    "is_oversized_valid = validate_request_size(oversized_request)\n",
    "print(f\"\\nOversized request size valid: {is_oversized_valid}\")\n",
    "print(f\"  Request size: ~{len(json.dumps(oversized_request).encode())} bytes\")\n",
    "print(f\"  Limit: {32 * 1024} bytes (32KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up and Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Clean up resources\nprint(\"=== Clean Up ===\")\n\n# Close the API client connection\nclient.close()\nprint(\"SUCCESS: API client connection closed\")\n\n# Summary of what we accomplished\nprint(\"\\n=== Summary ===\")\nprint(\"This notebook demonstrated:\")\nprint(\"SUCCESS: Customer.IO API client initialization and configuration\")\nprint(\"SUCCESS: API authentication and connection testing\")\nprint(\"SUCCESS: Request validation using Pydantic models\")\nprint(\"SUCCESS: Data transformation from Spark DataFrames to API requests\")\nprint(\"SUCCESS: Creating specialized ecommerce and mobile events\")\nprint(\"SUCCESS: Context object creation for different platforms\")\nprint(\"SUCCESS: Batch operations and size optimization\")\nprint(\"SUCCESS: Error handling patterns and retry logic\")\nprint(\"SUCCESS: Rate limiting demonstration\")\nprint(\"SUCCESS: Request size validation\")\n\nprint(\"\\nCOMPLETED: Ready to proceed to people management operations!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\nThis notebook has successfully demonstrated the Customer.IO API client and utility modules:\n\n### Key Accomplishments:\n\nSUCCESS: **API Client Initialized** - Production-ready client with rate limiting and error handling\n\nSUCCESS: **Request Validation** - Pydantic models ensure data integrity before API calls\n\nSUCCESS: **Data Transformation** - Seamless conversion from Spark DataFrames to API formats\n\nSUCCESS: **Specialized Events** - Easy creation of ecommerce and mobile app events\n\nSUCCESS: **Context Management** - Platform-specific context objects for rich event data\n\nSUCCESS: **Batch Operations** - Optimized batching with size limits and intelligent splitting\n\nSUCCESS: **Error Handling** - Comprehensive error handling with retry logic and graceful degradation\n\nSUCCESS: **Rate Limiting** - Built-in protection against API rate limits\n\n### Ready for Next Notebooks:\n\n1. **02_people_management.ipynb** - User identification, deletion, and lifecycle management\n2. **03_events_and_tracking.ipynb** - Event tracking and custom event implementation  \n3. **04_objects_and_relationships.ipynb** - Group/company management and relationships\n\n### Key Utilities Available:\n\n- **CustomerIOClient**: Production-ready API client with all features\n- **Validation Models**: Pydantic models for all API request types\n- **Transformers**: Data conversion utilities for Spark/Pandas to API formats\n- **Error Handlers**: Comprehensive error handling and retry mechanisms\n\nThe foundation is now solid for building comprehensive Customer.IO integrations in Databricks!",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}