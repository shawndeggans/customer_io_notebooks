{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer.IO Data Pipelines API - Setup and Configuration\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook establishes the foundation for working with Customer.IO's Data Pipelines API in Databricks.\n",
    "It covers environment setup, authentication configuration, Delta Lake table creation, and synthetic data generation for demonstrations.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Databricks Runtime 11.3 LTS or higher\n",
    "- Customer.IO API key (for test/sandbox environment)\n",
    "- Databricks secrets configured for API credentials\n",
    "- Cluster with Delta Lake enabled\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Customer.IO Data Pipelines API**: REST API for sending customer data and events\n",
    "- **Regional Endpoints**: Separate US and EU endpoints for data residency\n",
    "- **Rate Limits**: 3000 requests per 3 seconds\n",
    "- **Request Limits**: 32KB per request, 500KB per batch\n",
    "- **Delta Lake Integration**: Structured data storage for analytics and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Management - Production Ready with Version Constraints\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"httpx\": \">=0.25.0\",\n",
    "    \"pydantic\": \">=2.0.0\", \n",
    "    \"structlog\": \">=24.0.0\",\n",
    "    \"faker\": \">=20.0.0\",\n",
    "    \"python-dateutil\": \">=2.8.0\"\n",
    "}\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages with version constraints.\"\"\"\n",
    "    packages = [f\"{pkg}{version}\" for pkg, version in REQUIRED_PACKAGES.items()]\n",
    "    package_string = \" \".join(packages)\n",
    "    \n",
    "    print(\"Installing packages with version constraints:\")\n",
    "    for pkg, version in REQUIRED_PACKAGES.items():\n",
    "        print(f\"  {pkg} {version}\")\n",
    "    \n",
    "    return package_string\n",
    "\n",
    "# Prepare package installation\n",
    "package_string = install_packages()\n",
    "print(f\"SUCCESS: Package installation prepared - {len(REQUIRED_PACKAGES)} packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages and restart Python kernel\n",
    "\n",
    "%pip install {package_string}\n",
    "\n",
    "print(\"SUCCESS: Packages installed with version constraints\")\n",
    "print(\"INFO: Restarting Python kernel to use newly installed packages...\")\n",
    "\n",
    "# Restart Python kernel to use newly installed packages\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any\n",
    "import uuid\n",
    "\n",
    "# Databricks and Spark imports\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, BooleanType, DoubleType, ArrayType, MapType\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# HTTP and validation libraries\n",
    "import httpx\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import structlog\n",
    "\n",
    "# Data generation\n",
    "from faker import Faker\n",
    "from dateutil import tz\n",
    "\n",
    "# Initialize Faker for generating realistic test data\n",
    "fake = Faker()\n",
    "fake.seed_instance(42)  # For reproducible data\n",
    "\n",
    "# Initialize structured logging\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "print(\"SUCCESS: All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration widgets (non-sensitive data only)\n",
    "# SECURITY: Never expose API keys in widgets!\n",
    "\n",
    "dbutils.widgets.dropdown(\"customerio_region\", \"us\", [\"us\", \"eu\"], \"Customer.IO Region\")\n",
    "dbutils.widgets.text(\"database_name\", \"customerio_demo\", \"Database Name\") \n",
    "dbutils.widgets.text(\"catalog_name\", \"main\", \"Unity Catalog Name\")\n",
    "dbutils.widgets.dropdown(\"environment\", \"test\", [\"test\", \"sandbox\", \"production\"], \"Environment\")\n",
    "\n",
    "# Get configuration values\n",
    "CUSTOMERIO_REGION = dbutils.widgets.get(\"customerio_region\")\n",
    "DATABASE_NAME = dbutils.widgets.get(\"database_name\")\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\")\n",
    "ENVIRONMENT = dbutils.widgets.get(\"environment\")\n",
    "\n",
    "print(f\"Widget configuration:\")\n",
    "print(f\"  Region: {CUSTOMERIO_REGION}\")\n",
    "print(f\"  Database: {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "print(f\"  Environment: {ENVIRONMENT}\")\n",
    "print(\"SUCCESS: Configuration widgets set up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECURE: Get API key from Databricks secrets\n",
    "# This cell demonstrates proper secret management\n",
    "\n",
    "try:\n",
    "    if ENVIRONMENT == \"production\":\n",
    "        CUSTOMERIO_API_KEY = dbutils.secrets.get(scope=\"customerio\", key=\"production_api_key\")\n",
    "        secret_source = \"production secrets\"\n",
    "    elif ENVIRONMENT == \"sandbox\":\n",
    "        CUSTOMERIO_API_KEY = dbutils.secrets.get(scope=\"customerio\", key=\"sandbox_api_key\")\n",
    "        secret_source = \"sandbox secrets\"\n",
    "    else:\n",
    "        # Test environment - use mock key\n",
    "        CUSTOMERIO_API_KEY = \"test_key_demo_12345\"\n",
    "        secret_source = \"test mode\"\n",
    "        print(\"WARNING: Using test mode with mock API key\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to retrieve API key from secrets: {str(e)}\")\n",
    "    print(\"INFO: To configure secrets, run:\")\n",
    "    print(\"   databricks secrets create-scope customerio\")\n",
    "    print(\"   databricks secrets put customerio production_api_key\")\n",
    "    print(\"   databricks secrets put customerio sandbox_api_key\")\n",
    "    \n",
    "    # Fallback to test mode\n",
    "    CUSTOMERIO_API_KEY = \"test_key_demo_12345\"\n",
    "    ENVIRONMENT = \"test\"\n",
    "    secret_source = \"fallback test mode\"\n",
    "    print(\"INFO: Falling back to test mode\")\n",
    "\n",
    "print(f\"SUCCESS: API key retrieved from {secret_source}\")\n",
    "print(f\"Environment: {ENVIRONMENT}\")\n",
    "print(f\"API Key: {'SECURED' if ENVIRONMENT != 'test' else 'TEST_MODE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CustomerIOConfig from utils module for type safety\n",
    "# CustomerIOConfig will be extracted to utils for reusability\n",
    "\n",
    "from utils.validators import CustomerIOConfig\n",
    "\n",
    "# Test API key validation using the extracted utility\n",
    "def test_api_key_validation():\n",
    "    \"\"\"Test API key validation logic.\"\"\"\n",
    "    try:\n",
    "        # Test valid configuration\n",
    "        valid_config = CustomerIOConfig(api_key=CUSTOMERIO_API_KEY, region=CUSTOMERIO_REGION)\n",
    "        print(\"SUCCESS: Configuration validation passed\")\n",
    "        return valid_config\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Configuration validation failed: {str(e)}\")\n",
    "        # Create fallback test configuration\n",
    "        test_config = CustomerIOConfig(api_key=\"test_key_demo_12345\", region=\"us\")\n",
    "        print(\"INFO: Using fallback test configuration\")\n",
    "        return test_config\n",
    "\n",
    "# Initialize and validate configuration\n",
    "config = test_api_key_validation()\n",
    "\n",
    "print(f\"SUCCESS: Customer.IO API configured\")\n",
    "print(f\"   Base URL: {config.base_url}\")\n",
    "print(f\"   Rate Limit: {config.RATE_LIMIT_REQUESTS} requests per {config.RATE_LIMIT_WINDOW} seconds\")\n",
    "print(f\"   Max Request Size: {config.MAX_REQUEST_SIZE / 1024:.0f}KB\")\n",
    "print(f\"   Max Batch Size: {config.MAX_BATCH_SIZE / 1024:.0f}KB\")\n",
    "print(f\"   Headers configured: {len(config.get_headers())} headers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer.IO API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer.IO API Configuration with Type Safety and Validation\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import Dict, Literal\n",
    "\n",
    "class CustomerIOConfig(BaseModel):\n",
    "    \"\"\"Type-safe configuration class for Customer.IO API settings.\"\"\"\n",
    "    \n",
    "    api_key: str = Field(..., description=\"Customer.IO API key\")\n",
    "    region: Literal[\"us\", \"eu\"] = Field(default=\"us\", description=\"API region\")\n",
    "    \n",
    "    # Rate limiting configuration (class variables)\n",
    "    RATE_LIMIT_REQUESTS: int = 3000\n",
    "    RATE_LIMIT_WINDOW: int = 3  # seconds\n",
    "    \n",
    "    # Request size limits\n",
    "    MAX_REQUEST_SIZE: int = 32 * 1024  # 32KB\n",
    "    MAX_BATCH_SIZE: int = 500 * 1024   # 500KB\n",
    "    \n",
    "    # Retry configuration\n",
    "    MAX_RETRIES: int = 3\n",
    "    RETRY_BACKOFF_FACTOR: float = 2.0\n",
    "    \n",
    "    @validator('api_key')\n",
    "    def validate_api_key(cls, v: str) -> str:\n",
    "        \"\"\"Validate API key format.\"\"\"\n",
    "        if not v or len(v.strip()) == 0:\n",
    "            raise ValueError(\"API key cannot be empty\")\n",
    "        if len(v) < 10:  # Reasonable minimum length\n",
    "            raise ValueError(\"API key appears to be too short\")\n",
    "        return v.strip()\n",
    "    \n",
    "    @validator('region')\n",
    "    def validate_region(cls, v: str) -> str:\n",
    "        \"\"\"Validate and normalize region.\"\"\"\n",
    "        return v.lower()\n",
    "    \n",
    "    @property\n",
    "    def base_url(self) -> str:\n",
    "        \"\"\"Get base URL based on region.\"\"\"\n",
    "        if self.region == \"eu\":\n",
    "            return \"https://cdp-eu.customer.io/v1\"\n",
    "        else:\n",
    "            return \"https://cdp.customer.io/v1\"\n",
    "    \n",
    "    def get_headers(self) -> Dict[str, str]:\n",
    "        \"\"\"Get HTTP headers for API requests.\"\"\"\n",
    "        import base64\n",
    "        \n",
    "        # Customer.IO uses Basic Auth with API key as username, empty password\n",
    "        auth_string = base64.b64encode(f\"{self.api_key}:\".encode()).decode()\n",
    "        \n",
    "        return {\n",
    "            \"Authorization\": f\"Basic {auth_string}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": \"CustomerIO-Databricks-Notebooks/1.0.0\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration.\"\"\"\n",
    "        validate_assignment = True\n",
    "        extra = \"forbid\"\n",
    "\n",
    "# Test API key validation\n",
    "def test_api_key_validation():\n",
    "    \"\"\"Test API key validation logic.\"\"\"\n",
    "    try:\n",
    "        # Test valid configuration\n",
    "        valid_config = CustomerIOConfig(api_key=CUSTOMERIO_API_KEY, region=CUSTOMERIO_REGION)\n",
    "        print(\"SUCCESS: Configuration validation passed\")\n",
    "        return valid_config\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Configuration validation failed: {str(e)}\")\n",
    "        # Create fallback test configuration\n",
    "        test_config = CustomerIOConfig(api_key=\"test_key_demo_12345\", region=\"us\")\n",
    "        print(\"INFO: Using fallback test configuration\")\n",
    "        return test_config\n",
    "\n",
    "# Initialize and validate configuration\n",
    "config = test_api_key_validation()\n",
    "\n",
    "print(f\"SUCCESS: Customer.IO API configured\")\n",
    "print(f\"   Base URL: {config.base_url}\")\n",
    "print(f\"   Rate Limit: {config.RATE_LIMIT_REQUESTS} requests per {config.RATE_LIMIT_WINDOW} seconds\")\n",
    "print(f\"   Max Request Size: {config.MAX_REQUEST_SIZE / 1024:.0f}KB\")\n",
    "print(f\"   Max Batch Size: {config.MAX_BATCH_SIZE / 1024:.0f}KB\")\n",
    "print(f\"   Headers configured: {len(config.get_headers())} headers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database and Table Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database if it doesn't exist\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "spark.sql(f\"USE {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "\n",
    "print(f\"SUCCESS: Using database: {CATALOG_NAME}.{DATABASE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Lake Schema Definitions\n",
    "\n",
    "Define schemas for Delta Lake tables that align with Customer.IO API data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for customers table (aligns with /identify endpoint)\n",
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"anonymous_id\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "    StructField(\"updated_at\", TimestampType(), True),\n",
    "    StructField(\"traits\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"custom_attributes\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"is_active\", BooleanType(), True),\n",
    "    StructField(\"last_seen\", TimestampType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Schema for events table (aligns with /track endpoint)\n",
    "events_schema = StructType([\n",
    "    StructField(\"event_id\", StringType(), False),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"anonymous_id\", StringType(), True),\n",
    "    StructField(\"event_name\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"properties\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"context\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"is_semantic_event\", BooleanType(), True),\n",
    "    StructField(\"event_category\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"processed_at\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Schema for groups table (aligns with /group endpoint)\n",
    "groups_schema = StructType([\n",
    "    StructField(\"group_id\", StringType(), False),\n",
    "    StructField(\"group_type\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "    StructField(\"updated_at\", TimestampType(), True),\n",
    "    StructField(\"traits\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"parent_group_id\", StringType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "# Schema for devices table (device management)\n",
    "devices_schema = StructType([\n",
    "    StructField(\"device_id\", StringType(), False),\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"device_token\", StringType(), False),\n",
    "    StructField(\"device_type\", StringType(), False),  # ios, android, web\n",
    "    StructField(\"platform\", StringType(), True),\n",
    "    StructField(\"app_version\", StringType(), True),\n",
    "    StructField(\"os_version\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "    StructField(\"last_used\", TimestampType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "# Schema for API responses (logging and monitoring)\n",
    "api_responses_schema = StructType([\n",
    "    StructField(\"request_id\", StringType(), False),\n",
    "    StructField(\"endpoint\", StringType(), False),\n",
    "    StructField(\"method\", StringType(), False),\n",
    "    StructField(\"status_code\", IntegerType(), False),\n",
    "    StructField(\"response_time_ms\", IntegerType(), True),\n",
    "    StructField(\"request_size_bytes\", IntegerType(), True),\n",
    "    StructField(\"response_size_bytes\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"error_message\", StringType(), True),\n",
    "    StructField(\"retry_count\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Schema for batch operations tracking\n",
    "batch_operations_schema = StructType([\n",
    "    StructField(\"batch_id\", StringType(), False),\n",
    "    StructField(\"operation_type\", StringType(), False),\n",
    "    StructField(\"total_records\", IntegerType(), False),\n",
    "    StructField(\"successful_records\", IntegerType(), True),\n",
    "    StructField(\"failed_records\", IntegerType(), True),\n",
    "    StructField(\"started_at\", TimestampType(), False),\n",
    "    StructField(\"completed_at\", TimestampType(), True),\n",
    "    StructField(\"status\", StringType(), False),  # pending, processing, completed, failed\n",
    "    StructField(\"error_summary\", ArrayType(StringType()), True)\n",
    "])\n",
    "\n",
    "print(\"SUCCESS: Delta Lake schemas defined\")\n",
    "print(f\"   Customers schema: {len(customers_schema.fields)} fields\")\n",
    "print(f\"   Events schema: {len(events_schema.fields)} fields\")\n",
    "print(f\"   Groups schema: {len(groups_schema.fields)} fields\")\n",
    "print(f\"   Devices schema: {len(devices_schema.fields)} fields\")\n",
    "print(f\"   API responses schema: {len(api_responses_schema.fields)} fields\")\n",
    "print(f\"   Batch operations schema: {len(batch_operations_schema.fields)} fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Delta Lake Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import synthetic data generation utilities\n",
    "from utils.transformers import add_timestamp\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "def generate_synthetic_customers(num_customers: int = 1000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic customer data for testing.\n",
    "    \n",
    "    Args:\n",
    "        num_customers: Number of customers to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of customer dictionaries with required fields\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If num_customers is not positive\n",
    "        Exception: If data generation fails\n",
    "    \"\"\"\n",
    "    if num_customers <= 0:\n",
    "        raise ValueError(\"num_customers must be positive\")\n",
    "    \n",
    "    customers: List[Dict[str, Any]] = []\n",
    "    \n",
    "    try:\n",
    "        for i in range(num_customers):\n",
    "            customer_id = str(uuid.uuid4())\n",
    "            created_at = fake.date_time_between(start_date='-2y', end_date='now', tzinfo=tz.UTC)\n",
    "            \n",
    "            customer = {\n",
    "                \"customer_id\": customer_id,\n",
    "                \"user_id\": f\"user_{i+1:06d}\",\n",
    "                \"anonymous_id\": str(uuid.uuid4()) if fake.boolean(chance_of_getting_true=30) else None,\n",
    "                \"email\": fake.email(),\n",
    "                \"created_at\": created_at,\n",
    "                \"updated_at\": fake.date_time_between(start_date=created_at, end_date='now', tzinfo=tz.UTC),\n",
    "                \"traits\": {\n",
    "                    \"first_name\": fake.first_name(),\n",
    "                    \"last_name\": fake.last_name(),\n",
    "                    \"age\": str(fake.random_int(min=18, max=80)),\n",
    "                    \"city\": fake.city(),\n",
    "                    \"country\": fake.country(),\n",
    "                    \"plan\": fake.random_element([\"free\", \"basic\", \"premium\", \"enterprise\"]),\n",
    "                    \"signup_source\": fake.random_element([\"website\", \"mobile_app\", \"referral\", \"social\"])\n",
    "                },\n",
    "                \"custom_attributes\": {\n",
    "                    \"lifetime_value\": str(round(fake.random.uniform(0, 5000), 2)),\n",
    "                    \"last_purchase_amount\": str(round(fake.random.uniform(10, 500), 2)) if fake.boolean(chance_of_getting_true=60) else None,\n",
    "                    \"subscription_status\": fake.random_element([\"active\", \"canceled\", \"trial\", \"expired\"])\n",
    "                },\n",
    "                \"is_active\": fake.boolean(chance_of_getting_true=85),\n",
    "                \"last_seen\": fake.date_time_between(start_date='-30d', end_date='now', tzinfo=tz.UTC),\n",
    "                \"source\": \"synthetic_data\",\n",
    "                \"region\": CUSTOMERIO_REGION\n",
    "            }\n",
    "            customers.append(customer)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to generate customer data: {str(e)}\")\n",
    "    \n",
    "    return customers\n",
    "\n",
    "print(\"SUCCESS: Customer data generation function defined\")\n",
    "print(\"   Generates realistic customer profiles with traits and attributes\")\n",
    "print(\"   Includes validation and error handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full synthetic dataset for demonstrations\n",
    "\n",
    "print(\"Generating full synthetic dataset...\")\n",
    "try:\n",
    "    synthetic_customers = generate_synthetic_customers(1000)\n",
    "    synthetic_events = generate_synthetic_events(synthetic_customers, 5000)\n",
    "    \n",
    "    print(f\"SUCCESS: Generated synthetic data\")\n",
    "    print(f\"   Customers: {len(synthetic_customers):,}\")\n",
    "    print(f\"   Events: {len(synthetic_events):,}\")\n",
    "    print(f\"   Event categories: ecommerce, engagement, lifecycle, mobile\")\n",
    "    print(f\"   Data ready for Delta Lake loading\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Data generation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-driven approach: Test data generation functions\n",
    "\n",
    "def test_customer_generation():\n",
    "    \"\"\"Test customer data generation.\"\"\"\n",
    "    print(\"TEST: Testing customer data generation...\")\n",
    "    \n",
    "    # Test with valid parameters\n",
    "    test_customers = generate_synthetic_customers(5)\n",
    "    \n",
    "    # Validate structure\n",
    "    assert len(test_customers) == 5, \"Should generate exactly 5 customers\"\n",
    "    \n",
    "    for customer in test_customers:\n",
    "        # Test required fields\n",
    "        assert \"customer_id\" in customer, \"customer_id is required\"\n",
    "        assert \"user_id\" in customer, \"user_id is required\"\n",
    "        assert \"email\" in customer, \"email is required\"\n",
    "        assert \"traits\" in customer, \"traits is required\"\n",
    "        assert \"region\" in customer, \"region is required\"\n",
    "        \n",
    "        # Test data types\n",
    "        assert isinstance(customer[\"customer_id\"], str), \"customer_id should be string\"\n",
    "        assert isinstance(customer[\"traits\"], dict), \"traits should be dict\"\n",
    "        assert isinstance(customer[\"is_active\"], bool), \"is_active should be bool\"\n",
    "    \n",
    "    # Test error cases\n",
    "    try:\n",
    "        generate_synthetic_customers(0)\n",
    "        assert False, \"Should raise ValueError for zero customers\"\n",
    "    except ValueError:\n",
    "        pass  # Expected\n",
    "    \n",
    "    print(\"SUCCESS: Customer generation test passed\")\n",
    "    return test_customers\n",
    "\n",
    "def test_event_generation():\n",
    "    \"\"\"Test event data generation.\"\"\"\n",
    "    print(\"TEST: Testing event data generation...\")\n",
    "    \n",
    "    # Generate test customers first\n",
    "    test_customers = generate_synthetic_customers(3)\n",
    "    \n",
    "    # Test event generation\n",
    "    test_events = generate_synthetic_events(test_customers, 10)\n",
    "    \n",
    "    # Validate structure\n",
    "    assert len(test_events) == 10, \"Should generate exactly 10 events\"\n",
    "    \n",
    "    for event in test_events:\n",
    "        # Test required fields\n",
    "        assert \"event_id\" in event, \"event_id is required\"\n",
    "        assert \"event_name\" in event, \"event_name is required\"\n",
    "        assert \"customer_id\" in event, \"customer_id is required\"\n",
    "        assert \"timestamp\" in event, \"timestamp is required\"\n",
    "        assert \"event_category\" in event, \"event_category is required\"\n",
    "        \n",
    "        # Test data types\n",
    "        assert isinstance(event[\"event_id\"], str), \"event_id should be string\"\n",
    "        assert isinstance(event[\"properties\"], dict), \"properties should be dict\"\n",
    "        assert isinstance(event[\"context\"], dict), \"context should be dict\"\n",
    "        assert isinstance(event[\"is_semantic_event\"], bool), \"is_semantic_event should be bool\"\n",
    "    \n",
    "    # Test error cases\n",
    "    try:\n",
    "        generate_synthetic_events([], 5)\n",
    "        assert False, \"Should raise ValueError for empty customers\"\n",
    "    except ValueError:\n",
    "        pass  # Expected\n",
    "    \n",
    "    print(\"SUCCESS: Event generation test passed\")\n",
    "    return test_events\n",
    "\n",
    "# Run tests first to validate functionality\n",
    "print(\"Running data generation tests...\")\n",
    "test_customers = test_customer_generation()\n",
    "test_events = test_event_generation()\n",
    "print(\"SUCCESS: All data generation tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event generation function for comprehensive testing\n",
    "\n",
    "def generate_synthetic_events(customers: List[Dict[str, Any]], num_events: int = 5000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic event data for testing.\n",
    "    \n",
    "    Args:\n",
    "        customers: List of customer dictionaries\n",
    "        num_events: Number of events to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of event dictionaries with required fields\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If customers list is empty or num_events is not positive\n",
    "        Exception: If event generation fails\n",
    "    \"\"\"\n",
    "    if not customers:\n",
    "        raise ValueError(\"customers list cannot be empty\")\n",
    "    if num_events <= 0:\n",
    "        raise ValueError(\"num_events must be positive\")\n",
    "    \n",
    "    events: List[Dict[str, Any]] = []\n",
    "    \n",
    "    # Define event types and their categories\n",
    "    event_types = {\n",
    "        \"ecommerce\": [\n",
    "            \"Product Viewed\", \"Product Added\", \"Cart Viewed\", \"Checkout Started\", \n",
    "            \"Order Completed\", \"Product Removed\", \"Coupon Applied\"\n",
    "        ],\n",
    "        \"engagement\": [\n",
    "            \"Page Viewed\", \"Button Clicked\", \"Form Submitted\", \"Video Played\", \n",
    "            \"Document Downloaded\", \"Search Performed\"\n",
    "        ],\n",
    "        \"lifecycle\": [\n",
    "            \"User Registered\", \"Profile Updated\", \"Settings Changed\", \"Account Upgraded\", \n",
    "            \"Subscription Canceled\", \"Password Reset\"\n",
    "        ],\n",
    "        \"mobile\": [\n",
    "            \"Application Opened\", \"Application Backgrounded\", \"Push Notification Clicked\",\n",
    "            \"Screen Viewed\", \"Feature Used\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        for i in range(num_events):\n",
    "            customer = fake.random_element(customers)\n",
    "            category = fake.random_element(list(event_types.keys()))\n",
    "            event_name = fake.random_element(event_types[category])\n",
    "            \n",
    "            # Generate event properties based on category\n",
    "            properties: Dict[str, str] = {}\n",
    "            if category == \"ecommerce\":\n",
    "                properties.update({\n",
    "                    \"product_id\": f\"prod_{fake.random_int(min=1, max=1000)}\",\n",
    "                    \"product_name\": fake.catch_phrase(),\n",
    "                    \"price\": str(round(fake.random.uniform(9.99, 299.99), 2)),\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"category\": fake.random_element([\"electronics\", \"clothing\", \"books\", \"home\", \"sports\"])\n",
    "                })\n",
    "            elif category == \"engagement\":\n",
    "                properties.update({\n",
    "                    \"page_url\": fake.url(),\n",
    "                    \"referrer\": fake.url() if fake.boolean(chance_of_getting_true=30) else \"\",\n",
    "                    \"session_id\": str(uuid.uuid4())\n",
    "                })\n",
    "            \n",
    "            event = {\n",
    "                \"event_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer[\"customer_id\"],\n",
    "                \"user_id\": customer[\"user_id\"],\n",
    "                \"anonymous_id\": customer.get(\"anonymous_id\"),\n",
    "                \"event_name\": event_name,\n",
    "                \"timestamp\": fake.date_time_between(start_date='-90d', end_date='now', tzinfo=tz.UTC),\n",
    "                \"properties\": properties,\n",
    "                \"context\": {\n",
    "                    \"ip\": fake.ipv4(),\n",
    "                    \"user_agent\": fake.user_agent(),\n",
    "                    \"locale\": fake.locale(),\n",
    "                    \"timezone\": str(fake.timezone())\n",
    "                },\n",
    "                \"is_semantic_event\": event_name in [item for sublist in event_types.values() for item in sublist[:3]],\n",
    "                \"event_category\": category,\n",
    "                \"source\": \"synthetic_data\",\n",
    "                \"processed_at\": datetime.now(tz.UTC)\n",
    "            }\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to generate event data: {str(e)}\")\n",
    "    \n",
    "    return events\n",
    "\n",
    "print(\"SUCCESS: Event data generation function defined\")\n",
    "print(\"   Generates events across 4 categories with realistic properties\")\n",
    "print(\"   Includes semantic event identification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import validation utilities from utils module for reusability\n",
    "from utils.error_handlers import CircuitBreaker\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Type-safe validation result.\"\"\"\n",
    "    status: str  # \"SUCCESS\", \"ERROR\", \"WARNING\"\n",
    "    component: str\n",
    "    result: str\n",
    "    error: Optional[Exception] = None\n",
    "\n",
    "# Initialize circuit breaker for validation operations\n",
    "validation_breaker = CircuitBreaker(failure_threshold=2, timeout=30)\n",
    "\n",
    "print(\"SUCCESS: Validation utilities imported and configured\")\n",
    "print(\"   Circuit breaker configured for fault tolerance\")\n",
    "print(\"   ValidationResult dataclass defined for type safety\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute validation and display results\n",
    "\n",
    "def display_validation_results(validations: List[ValidationResult]) -> Dict[str, Any]:\n",
    "    \"\"\"Display validation results and calculate summary.\"\"\"\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"Setup Validation Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for validation in validations:\n",
    "        print(f\"{validation.status} {validation.component:<25} {validation.result}\")\n",
    "        if validation.error and validation.status == \"ERROR\":\n",
    "            print(f\"    Error: {type(validation.error).__name__}: {str(validation.error)}\")\n",
    "    \n",
    "    # Calculate summary\n",
    "    passed = sum(1 for v in validations if v.status == \"SUCCESS\")\n",
    "    warnings = sum(1 for v in validations if v.status == \"WARNING\")\n",
    "    failed = sum(1 for v in validations if v.status == \"ERROR\")\n",
    "    total = len(validations)\n",
    "    \n",
    "    print(f\"\\nValidation Summary:\")\n",
    "    print(f\"  SUCCESS: Passed: {passed}\")\n",
    "    print(f\"  WARNING: Warnings: {warnings}\")\n",
    "    print(f\"  ERROR: Failed: {failed}\")\n",
    "    print(f\"  DATA: Total: {total}\")\n",
    "    \n",
    "    # Determine overall status\n",
    "    if failed == 0:\n",
    "        if warnings == 0:\n",
    "            print(\"COMPLETED: All validation checks passed! Ready to proceed.\")\n",
    "            overall_status = \"success\"\n",
    "        else:\n",
    "            print(\"WARNING: Validation passed with warnings. Review before proceeding.\")\n",
    "            overall_status = \"warning\"\n",
    "    else:\n",
    "        print(\"ERROR: Some validation checks failed. Please fix issues before proceeding.\")\n",
    "        overall_status = \"failed\"\n",
    "    \n",
    "    return {\n",
    "        \"overall_status\": overall_status,\n",
    "        \"passed\": passed,\n",
    "        \"warnings\": warnings,\n",
    "        \"failed\": failed,\n",
    "        \"total\": total,\n",
    "        \"validations\": validations,\n",
    "        \"circuit_breaker_state\": validation_breaker.state\n",
    "    }\n",
    "\n",
    "# Run validation and display results\n",
    "validations = validate_setup()\n",
    "validation_results = display_validation_results(validations)\n",
    "\n",
    "# Raise exception if critical validations failed\n",
    "if validation_results[\"overall_status\"] == \"failed\":\n",
    "    critical_failures = [v for v in validations \n",
    "                       if v.status == \"ERROR\" and \"Database\" in v.component]\n",
    "    \n",
    "    if critical_failures:\n",
    "        raise Exception(\"Critical validation failures detected - cannot proceed\")\n",
    "\n",
    "print(\"\\nSUCCESS: Setup validation completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive setup validation with circuit breaker protection\n",
    "\n",
    "def validate_setup() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive setup validation with error handling and circuit breaker.\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing validation results and summary\n",
    "    \"\"\"\n",
    "    print(\"ANALYSIS: Running comprehensive setup validation...\")\n",
    "    \n",
    "    validations: List[ValidationResult] = []\n",
    "    \n",
    "    # Database validation\n",
    "    try:\n",
    "        result = validation_breaker(validate_database_access)\n",
    "        validations.append(result)\n",
    "    except Exception as e:\n",
    "        validations.append(ValidationResult(\"ERROR\", \"Database access\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # Table validation\n",
    "    required_tables = [\"customers\", \"events\", \"groups\", \"devices\", \"api_responses\", \"batch_operations\"]\n",
    "    for table in required_tables:\n",
    "        try:\n",
    "            result = validation_breaker(validate_table_exists, table)\n",
    "            validations.append(result)\n",
    "        except Exception as e:\n",
    "            validations.append(ValidationResult(\"ERROR\", f\"Table {table}\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # Data quality validation\n",
    "    data_tables = [\"customers\", \"events\"]\n",
    "    for table in data_tables:\n",
    "        try:\n",
    "            result = validation_breaker(validate_data_quality, table)\n",
    "            validations.append(result)\n",
    "        except Exception as e:\n",
    "            validations.append(ValidationResult(\"ERROR\", f\"{table} data\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # API configuration validation\n",
    "    try:\n",
    "        result = validation_breaker(validate_api_configuration)\n",
    "        validations.append(result)\n",
    "    except Exception as e:\n",
    "        validations.append(ValidationResult(\"ERROR\", \"API configuration\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    return validations\n",
    "\n",
    "print(\"SUCCESS: Comprehensive validation function defined\")\n",
    "print(\"   Includes circuit breaker protection for fault tolerance\")\n",
    "print(\"   Validates database, tables, data quality, and API configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define individual validation functions with error handling\n",
    "\n",
    "def validate_database_access() -> ValidationResult:\n",
    "    \"\"\"Validate database access with error handling.\"\"\"\n",
    "    try:\n",
    "        spark.sql(f\"USE {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "        return ValidationResult(\"SUCCESS\", \"Database access\", \"OK\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", \"Database access\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "def validate_table_exists(table_name: str) -> ValidationResult:\n",
    "    \"\"\"Validate that a table exists.\"\"\"\n",
    "    try:\n",
    "        spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.{table_name}\")\n",
    "        return ValidationResult(\"SUCCESS\", f\"Table {table_name}\", \"Exists\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", f\"Table {table_name}\", \"Missing\", e)\n",
    "\n",
    "def validate_data_quality(table_name: str) -> ValidationResult:\n",
    "    \"\"\"Validate data quality in a table.\"\"\"\n",
    "    try:\n",
    "        df = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.{table_name}\")\n",
    "        count = df.count()\n",
    "        \n",
    "        if count > 0:\n",
    "            return ValidationResult(\"SUCCESS\", f\"{table_name} data\", f\"{count} records\")\n",
    "        else:\n",
    "            return ValidationResult(\"WARNING\", f\"{table_name} data\", \"No records\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", f\"{table_name} data\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "def validate_api_configuration() -> ValidationResult:\n",
    "    \"\"\"Validate API configuration.\"\"\"\n",
    "    try:\n",
    "        if not config.api_key:\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Missing API key\")\n",
    "        \n",
    "        if not config.base_url:\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Missing base URL\")\n",
    "        \n",
    "        # Test header generation\n",
    "        headers = config.get_headers()\n",
    "        if not headers.get(\"Authorization\"):\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Invalid authorization header\")\n",
    "        \n",
    "        if ENVIRONMENT == \"test\":\n",
    "            return ValidationResult(\"WARNING\", \"API configuration\", \"Test mode - mock key\")\n",
    "        else:\n",
    "            return ValidationResult(\"SUCCESS\", \"API configuration\", \"Valid\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", \"API configuration\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "print(\"SUCCESS: Individual validation functions defined\")\n",
    "print(\"   Database access validation\")\n",
    "print(\"   Table existence validation\") \n",
    "print(\"   Data quality validation\")\n",
    "print(\"   API configuration validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type-safe synthetic data generation with comprehensive testing\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "def generate_synthetic_customers(num_customers: int = 1000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic customer data for testing.\n",
    "    \n",
    "    Args:\n",
    "        num_customers: Number of customers to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of customer dictionaries with required fields\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If num_customers is not positive\n",
    "        Exception: If data generation fails\n",
    "    \"\"\"\n",
    "    if num_customers <= 0:\n",
    "        raise ValueError(\"num_customers must be positive\")\n",
    "    \n",
    "    customers: List[Dict[str, Any]] = []\n",
    "    \n",
    "    try:\n",
    "        for i in range(num_customers):\n",
    "            customer_id = str(uuid.uuid4())\n",
    "            created_at = fake.date_time_between(start_date='-2y', end_date='now', tzinfo=tz.UTC)\n",
    "            \n",
    "            customer = {\n",
    "                \"customer_id\": customer_id,\n",
    "                \"user_id\": f\"user_{i+1:06d}\",\n",
    "                \"anonymous_id\": str(uuid.uuid4()) if fake.boolean(chance_of_getting_true=30) else None,\n",
    "                \"email\": fake.email(),\n",
    "                \"created_at\": created_at,\n",
    "                \"updated_at\": fake.date_time_between(start_date=created_at, end_date='now', tzinfo=tz.UTC),\n",
    "                \"traits\": {\n",
    "                    \"first_name\": fake.first_name(),\n",
    "                    \"last_name\": fake.last_name(),\n",
    "                    \"age\": str(fake.random_int(min=18, max=80)),\n",
    "                    \"city\": fake.city(),\n",
    "                    \"country\": fake.country(),\n",
    "                    \"plan\": fake.random_element([\"free\", \"basic\", \"premium\", \"enterprise\"]),\n",
    "                    \"signup_source\": fake.random_element([\"website\", \"mobile_app\", \"referral\", \"social\"])\n",
    "                },\n",
    "                \"custom_attributes\": {\n",
    "                    \"lifetime_value\": str(round(fake.random.uniform(0, 5000), 2)),\n",
    "                    \"last_purchase_amount\": str(round(fake.random.uniform(10, 500), 2)) if fake.boolean(chance_of_getting_true=60) else None,\n",
    "                    \"subscription_status\": fake.random_element([\"active\", \"canceled\", \"trial\", \"expired\"])\n",
    "                },\n",
    "                \"is_active\": fake.boolean(chance_of_getting_true=85),\n",
    "                \"last_seen\": fake.date_time_between(start_date='-30d', end_date='now', tzinfo=tz.UTC),\n",
    "                \"source\": \"synthetic_data\",\n",
    "                \"region\": CUSTOMERIO_REGION\n",
    "            }\n",
    "            customers.append(customer)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to generate customer data: {str(e)}\")\n",
    "    \n",
    "    return customers\n",
    "\n",
    "def generate_synthetic_events(customers: List[Dict[str, Any]], num_events: int = 5000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic event data for testing.\n",
    "    \n",
    "    Args:\n",
    "        customers: List of customer dictionaries\n",
    "        num_events: Number of events to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of event dictionaries with required fields\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If customers list is empty or num_events is not positive\n",
    "        Exception: If event generation fails\n",
    "    \"\"\"\n",
    "    if not customers:\n",
    "        raise ValueError(\"customers list cannot be empty\")\n",
    "    if num_events <= 0:\n",
    "        raise ValueError(\"num_events must be positive\")\n",
    "    \n",
    "    events: List[Dict[str, Any]] = []\n",
    "    \n",
    "    # Define event types and their categories\n",
    "    event_types = {\n",
    "        \"ecommerce\": [\n",
    "            \"Product Viewed\", \"Product Added\", \"Cart Viewed\", \"Checkout Started\", \n",
    "            \"Order Completed\", \"Product Removed\", \"Coupon Applied\"\n",
    "        ],\n",
    "        \"engagement\": [\n",
    "            \"Page Viewed\", \"Button Clicked\", \"Form Submitted\", \"Video Played\", \n",
    "            \"Document Downloaded\", \"Search Performed\"\n",
    "        ],\n",
    "        \"lifecycle\": [\n",
    "            \"User Registered\", \"Profile Updated\", \"Settings Changed\", \"Account Upgraded\", \n",
    "            \"Subscription Canceled\", \"Password Reset\"\n",
    "        ],\n",
    "        \"mobile\": [\n",
    "            \"Application Opened\", \"Application Backgrounded\", \"Push Notification Clicked\",\n",
    "            \"Screen Viewed\", \"Feature Used\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        for i in range(num_events):\n",
    "            customer = fake.random_element(customers)\n",
    "            category = fake.random_element(list(event_types.keys()))\n",
    "            event_name = fake.random_element(event_types[category])\n",
    "            \n",
    "            # Generate event properties based on category\n",
    "            properties: Dict[str, str] = {}\n",
    "            if category == \"ecommerce\":\n",
    "                properties.update({\n",
    "                    \"product_id\": f\"prod_{fake.random_int(min=1, max=1000)}\",\n",
    "                    \"product_name\": fake.catch_phrase(),\n",
    "                    \"price\": str(round(fake.random.uniform(9.99, 299.99), 2)),\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"category\": fake.random_element([\"electronics\", \"clothing\", \"books\", \"home\", \"sports\"])\n",
    "                })\n",
    "            elif category == \"engagement\":\n",
    "                properties.update({\n",
    "                    \"page_url\": fake.url(),\n",
    "                    \"referrer\": fake.url() if fake.boolean(chance_of_getting_true=30) else \"\",\n",
    "                    \"session_id\": str(uuid.uuid4())\n",
    "                })\n",
    "            \n",
    "            event = {\n",
    "                \"event_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer[\"customer_id\"],\n",
    "                \"user_id\": customer[\"user_id\"],\n",
    "                \"anonymous_id\": customer.get(\"anonymous_id\"),\n",
    "                \"event_name\": event_name,\n",
    "                \"timestamp\": fake.date_time_between(start_date='-90d', end_date='now', tzinfo=tz.UTC),\n",
    "                \"properties\": properties,\n",
    "                \"context\": {\n",
    "                    \"ip\": fake.ipv4(),\n",
    "                    \"user_agent\": fake.user_agent(),\n",
    "                    \"locale\": fake.locale(),\n",
    "                    \"timezone\": str(fake.timezone())\n",
    "                },\n",
    "                \"is_semantic_event\": event_name in [item for sublist in event_types.values() for item in sublist[:3]],\n",
    "                \"event_category\": category,\n",
    "                \"source\": \"synthetic_data\",\n",
    "                \"processed_at\": datetime.now(tz.UTC)\n",
    "            }\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to generate event data: {str(e)}\")\n",
    "    \n",
    "    return events\n",
    "\n",
    "# Test-driven approach: Test data generation functions\n",
    "def test_customer_generation():\n",
    "    \"\"\"Test customer data generation.\"\"\"\n",
    "    print(\"TEST: Testing customer data generation...\")\n",
    "    \n",
    "    # Test with valid parameters\n",
    "    test_customers = generate_synthetic_customers(5)\n",
    "    \n",
    "    # Validate structure\n",
    "    assert len(test_customers) == 5, \"Should generate exactly 5 customers\"\n",
    "    \n",
    "    for customer in test_customers:\n",
    "        # Test required fields\n",
    "        assert \"customer_id\" in customer, \"customer_id is required\"\n",
    "        assert \"user_id\" in customer, \"user_id is required\"\n",
    "        assert \"email\" in customer, \"email is required\"\n",
    "        assert \"traits\" in customer, \"traits is required\"\n",
    "        assert \"region\" in customer, \"region is required\"\n",
    "        \n",
    "        # Test data types\n",
    "        assert isinstance(customer[\"customer_id\"], str), \"customer_id should be string\"\n",
    "        assert isinstance(customer[\"traits\"], dict), \"traits should be dict\"\n",
    "        assert isinstance(customer[\"is_active\"], bool), \"is_active should be bool\"\n",
    "    \n",
    "    # Test error cases\n",
    "    try:\n",
    "        generate_synthetic_customers(0)\n",
    "        assert False, \"Should raise ValueError for zero customers\"\n",
    "    except ValueError:\n",
    "        pass  # Expected\n",
    "    \n",
    "    print(\"SUCCESS: Customer generation test passed\")\n",
    "    return test_customers\n",
    "\n",
    "def test_event_generation():\n",
    "    \"\"\"Test event data generation.\"\"\"\n",
    "    print(\"TEST: Testing event data generation...\")\n",
    "    \n",
    "    # Generate test customers first\n",
    "    test_customers = generate_synthetic_customers(3)\n",
    "    \n",
    "    # Test event generation\n",
    "    test_events = generate_synthetic_events(test_customers, 10)\n",
    "    \n",
    "    # Validate structure\n",
    "    assert len(test_events) == 10, \"Should generate exactly 10 events\"\n",
    "    \n",
    "    for event in test_events:\n",
    "        # Test required fields\n",
    "        assert \"event_id\" in event, \"event_id is required\"\n",
    "        assert \"event_name\" in event, \"event_name is required\"\n",
    "        assert \"customer_id\" in event, \"customer_id is required\"\n",
    "        assert \"timestamp\" in event, \"timestamp is required\"\n",
    "        assert \"event_category\" in event, \"event_category is required\"\n",
    "        \n",
    "        # Test data types\n",
    "        assert isinstance(event[\"event_id\"], str), \"event_id should be string\"\n",
    "        assert isinstance(event[\"properties\"], dict), \"properties should be dict\"\n",
    "        assert isinstance(event[\"context\"], dict), \"context should be dict\"\n",
    "        assert isinstance(event[\"is_semantic_event\"], bool), \"is_semantic_event should be bool\"\n",
    "    \n",
    "    # Test error cases\n",
    "    try:\n",
    "        generate_synthetic_events([], 5)\n",
    "        assert False, \"Should raise ValueError for empty customers\"\n",
    "    except ValueError:\n",
    "        pass  # Expected\n",
    "    \n",
    "    print(\"SUCCESS: Event generation test passed\")\n",
    "    return test_events\n",
    "\n",
    "# Run tests and generate data\n",
    "print(\"Running data generation tests...\")\n",
    "test_customers = test_customer_generation()\n",
    "test_events = test_event_generation()\n",
    "\n",
    "print(\"\\nGenerating full synthetic dataset...\")\n",
    "try:\n",
    "    synthetic_customers = generate_synthetic_customers(1000)\n",
    "    synthetic_events = generate_synthetic_events(synthetic_customers, 5000)\n",
    "    print(f\"SUCCESS: Generated {len(synthetic_customers)} customers and {len(synthetic_events)} events\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Data generation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Synthetic Data into Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert synthetic data to Spark DataFrames and load into Delta tables\n",
    "\n",
    "# Load customers data\n",
    "customers_df = spark.createDataFrame(synthetic_customers, customers_schema)\n",
    "customers_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{CATALOG_NAME}.{DATABASE_NAME}.customers\")\n",
    "\n",
    "# Load events data\n",
    "events_df = spark.createDataFrame(synthetic_events, events_schema)\n",
    "events_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{CATALOG_NAME}.{DATABASE_NAME}.events\")\n",
    "\n",
    "print(\"SUCCESS: Synthetic data loaded into Delta tables\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample customer data:\")\n",
    "spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.customers\").select(\"customer_id\", \"email\", \"traits\", \"is_active\").show(3, truncate=False)\n",
    "\n",
    "print(\"\\nSample event data:\")\n",
    "spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.events\").select(\"event_name\", \"customer_id\", \"timestamp\", \"event_category\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive validation with error handling and circuit breaker patterns\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Type-safe validation result.\"\"\"\n",
    "    status: str  # \"SUCCESS\", \"ERROR\", \"WARNING\"\n",
    "    component: str\n",
    "    result: str\n",
    "    error: Optional[Exception] = None\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker for validation operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 3, timeout: int = 60):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = 0\n",
    "        self.state = \"closed\"  # closed, open, half-open\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function with circuit breaker protection.\"\"\"\n",
    "        if self.state == \"open\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"half-open\"\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker is open\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            if self.state == \"half-open\":\n",
    "                self.state = \"closed\"\n",
    "                self.failure_count = 0\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.failure_count += 1\n",
    "            self.last_failure_time = time.time()\n",
    "            \n",
    "            if self.failure_count >= self.failure_threshold:\n",
    "                self.state = \"open\"\n",
    "            \n",
    "            raise e\n",
    "\n",
    "# Initialize circuit breaker for validation\n",
    "validation_breaker = CircuitBreaker(failure_threshold=2, timeout=30)\n",
    "\n",
    "def validate_database_access() -> ValidationResult:\n",
    "    \"\"\"Validate database access with error handling.\"\"\"\n",
    "    try:\n",
    "        spark.sql(f\"USE {CATALOG_NAME}.{DATABASE_NAME}\")\n",
    "        return ValidationResult(\"SUCCESS\", \"Database access\", \"OK\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", \"Database access\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "def validate_table_exists(table_name: str) -> ValidationResult:\n",
    "    \"\"\"Validate that a table exists.\"\"\"\n",
    "    try:\n",
    "        spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.{table_name}\")\n",
    "        return ValidationResult(\"SUCCESS\", f\"Table {table_name}\", \"Exists\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", f\"Table {table_name}\", \"Missing\", e)\n",
    "\n",
    "def validate_data_quality(table_name: str) -> ValidationResult:\n",
    "    \"\"\"Validate data quality in a table.\"\"\"\n",
    "    try:\n",
    "        df = spark.table(f\"{CATALOG_NAME}.{DATABASE_NAME}.{table_name}\")\n",
    "        count = df.count()\n",
    "        \n",
    "        if count > 0:\n",
    "            return ValidationResult(\"SUCCESS\", f\"{table_name} data\", f\"{count} records\")\n",
    "        else:\n",
    "            return ValidationResult(\"WARNING\", f\"{table_name} data\", \"No records\")\n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", f\"{table_name} data\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "def validate_api_configuration() -> ValidationResult:\n",
    "    \"\"\"Validate API configuration.\"\"\"\n",
    "    try:\n",
    "        if not config.api_key:\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Missing API key\")\n",
    "        \n",
    "        if not config.base_url:\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Missing base URL\")\n",
    "        \n",
    "        # Test header generation\n",
    "        headers = config.get_headers()\n",
    "        if not headers.get(\"Authorization\"):\n",
    "            return ValidationResult(\"ERROR\", \"API configuration\", \"Invalid authorization header\")\n",
    "        \n",
    "        if ENVIRONMENT == \"test\":\n",
    "            return ValidationResult(\"WARNING\", \"API configuration\", \"Test mode - mock key\")\n",
    "        else:\n",
    "            return ValidationResult(\"SUCCESS\", \"API configuration\", \"Valid\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        return ValidationResult(\"ERROR\", \"API configuration\", f\"Failed: {str(e)}\", e)\n",
    "\n",
    "def validate_setup() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive setup validation with error handling and circuit breaker.\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing validation results and summary\n",
    "    \"\"\"\n",
    "    print(\"ANALYSIS: Running comprehensive setup validation...\")\n",
    "    \n",
    "    validations: List[ValidationResult] = []\n",
    "    \n",
    "    # Database validation\n",
    "    try:\n",
    "        result = validation_breaker.call(validate_database_access)\n",
    "        validations.append(result)\n",
    "    except Exception as e:\n",
    "        validations.append(ValidationResult(\"ERROR\", \"Database access\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # Table validation\n",
    "    required_tables = [\"customers\", \"events\", \"groups\", \"devices\", \"api_responses\", \"batch_operations\"]\n",
    "    for table in required_tables:\n",
    "        try:\n",
    "            result = validation_breaker.call(validate_table_exists, table)\n",
    "            validations.append(result)\n",
    "        except Exception as e:\n",
    "            validations.append(ValidationResult(\"ERROR\", f\"Table {table}\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # Data quality validation\n",
    "    data_tables = [\"customers\", \"events\"]\n",
    "    for table in data_tables:\n",
    "        try:\n",
    "            result = validation_breaker.call(validate_data_quality, table)\n",
    "            validations.append(result)\n",
    "        except Exception as e:\n",
    "            validations.append(ValidationResult(\"ERROR\", f\"{table} data\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # API configuration validation\n",
    "    try:\n",
    "        result = validation_breaker.call(validate_api_configuration)\n",
    "        validations.append(result)\n",
    "    except Exception as e:\n",
    "        validations.append(ValidationResult(\"ERROR\", \"API configuration\", f\"Circuit breaker: {str(e)}\", e))\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"Setup Validation Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for validation in validations:\n",
    "        print(f\"{validation.status} {validation.component:<25} {validation.result}\")\n",
    "        if validation.error and validation.status == \"ERROR\":\n",
    "            print(f\"    Error: {type(validation.error).__name__}: {str(validation.error)}\")\n",
    "    \n",
    "    # Calculate summary\n",
    "    passed = sum(1 for v in validations if v.status == \"SUCCESS\")\n",
    "    warnings = sum(1 for v in validations if v.status == \"WARNING\")\n",
    "    failed = sum(1 for v in validations if v.status == \"ERROR\")\n",
    "    total = len(validations)\n",
    "    \n",
    "    print(f\"\\nValidation Summary:\")\n",
    "    print(f\"  SUCCESS: Passed: {passed}\")\n",
    "    print(f\"  WARNING: Warnings: {warnings}\")\n",
    "    print(f\"  ERROR: Failed: {failed}\")\n",
    "    print(f\"  DATA: Total: {total}\")\n",
    "    \n",
    "    # Determine overall status\n",
    "    if failed == 0:\n",
    "        if warnings == 0:\n",
    "            print(\"COMPLETED: All validation checks passed! Ready to proceed.\")\n",
    "            overall_status = \"success\"\n",
    "        else:\n",
    "            print(\"WARNING: Validation passed with warnings. Review before proceeding.\")\n",
    "            overall_status = \"warning\"\n",
    "    else:\n",
    "        print(\"ERROR: Some validation checks failed. Please fix issues before proceeding.\")\n",
    "        overall_status = \"failed\"\n",
    "    \n",
    "    # Return detailed results for programmatic use\n",
    "    return {\n",
    "        \"overall_status\": overall_status,\n",
    "        \"passed\": passed,\n",
    "        \"warnings\": warnings,\n",
    "        \"failed\": failed,\n",
    "        \"total\": total,\n",
    "        \"validations\": validations,\n",
    "        \"circuit_breaker_state\": validation_breaker.state\n",
    "    }\n",
    "\n",
    "def test_validation_function():\n",
    "    \"\"\"Test the validation function itself.\"\"\"\n",
    "    print(\"TEST: Testing validation function...\")\n",
    "    \n",
    "    try:\n",
    "        # Test validation function\n",
    "        results = validate_setup()\n",
    "        \n",
    "        # Validate structure\n",
    "        assert \"overall_status\" in results, \"overall_status is required\"\n",
    "        assert \"validations\" in results, \"validations is required\"\n",
    "        assert isinstance(results[\"validations\"], list), \"validations should be list\"\n",
    "        \n",
    "        # Test that we have some validations\n",
    "        assert len(results[\"validations\"]) > 0, \"Should have validation results\"\n",
    "        \n",
    "        # Test ValidationResult structure\n",
    "        for validation in results[\"validations\"]:\n",
    "            assert hasattr(validation, \"status\"), \"ValidationResult should have status\"\n",
    "            assert hasattr(validation, \"component\"), \"ValidationResult should have component\"\n",
    "            assert hasattr(validation, \"result\"), \"ValidationResult should have result\"\n",
    "        \n",
    "        print(\"SUCCESS: Validation function test passed\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Validation function test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test and run validation\n",
    "if test_validation_function():\n",
    "    validation_results = validate_setup()\n",
    "    \n",
    "    # Raise exception if critical validations failed\n",
    "    if validation_results[\"overall_status\"] == \"failed\":\n",
    "        critical_failures = [v for v in validation_results[\"validations\"] \n",
    "                           if v.status == \"ERROR\" and \"Database\" in v.component]\n",
    "        \n",
    "        if critical_failures:\n",
    "            raise Exception(\"Critical validation failures detected - cannot proceed\")\n",
    "else:\n",
    "    raise Exception(\"Validation function test failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Configuration Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display recommended cluster configuration\n",
    "print(\"Recommended Databricks Cluster Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "recommended_config = {\n",
    "    \"Databricks Runtime\": \"11.3.x-scala2.12 or higher\",\n",
    "    \"Node Type (Driver)\": \"Standard_DS3_v2 (14 GB Memory, 4 Cores)\",\n",
    "    \"Node Type (Workers)\": \"Standard_DS3_v2 (14 GB Memory, 4 Cores)\",\n",
    "    \"Workers\": \"2-4 (autoscaling enabled)\",\n",
    "    \"Auto Termination\": \"120 minutes\",\n",
    "    \"Spark Config\": {\n",
    "        \"spark.sql.adaptive.enabled\": \"true\",\n",
    "        \"spark.sql.adaptive.coalescePartitions.enabled\": \"true\",\n",
    "        \"spark.sql.adaptive.coalescePartitions.minPartitionNum\": \"1\",\n",
    "        \"spark.sql.adaptive.coalescePartitions.initialPartitionNum\": \"200\",\n",
    "        \"spark.sql.adaptive.skewJoin.enabled\": \"true\",\n",
    "        \"spark.databricks.delta.preview.enabled\": \"true\",\n",
    "        \"spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite\": \"true\",\n",
    "        \"spark.databricks.delta.properties.defaults.autoOptimize.autoCompact\": \"true\"\n",
    "    },\n",
    "    \"Environment Variables\": {\n",
    "        \"CUSTOMERIO_REGION\": CUSTOMERIO_REGION,\n",
    "        \"DATABRICKS_ENV\": ENVIRONMENT\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, value in recommended_config.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nNOTE: These configurations are optimized for Customer.IO API workloads\")\n",
    "print(\"   with Delta Lake and structured streaming capabilities.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
